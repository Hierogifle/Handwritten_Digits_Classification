{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da782ee",
   "metadata": {},
   "source": [
    "# üì¶ CELLULE 1 : Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02855e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                   MNIST CNN - Classification de Chiffres                 ‚ïë\n",
    "‚ïë                                                                          ‚ïë\n",
    "‚ïë  Objectif : Entra√Æner un CNN performant pour classifier les chiffres     ‚ïë\n",
    "‚ïë             manuscrits avec optimisation bay√©sienne des hyperparam√®tres  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Librairies de base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch - Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# M√©triques et √©valuation\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    confusion_matrix,\n",
    "    classification_report, \n",
    "    silhouette_score,\n",
    "    davies_bouldin_score\n",
    ")\n",
    "\n",
    "# R√©duction de dimensionnalit√©\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Optimisation bay√©sienne\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances, plot_optimization_history\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# D√©tection automatique du device (GPU si disponible, sinon CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Device configur√© : {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU d√©tect√© : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   M√©moire disponible : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Seed pour reproductibilit√©\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# ============================================================================\n",
    "# CHEMINS DES FICHIERS\n",
    "# ============================================================================\n",
    "\n",
    "# Adapter selon ton environnement (Google Colab vs local)\n",
    "DRIVE_PATH = Path('/content/drive/MyDrive/La Plateforme/Handwritten Digits')\n",
    "DATA_TRAIN_PATH = DRIVE_PATH / 'mnist_train.csv'\n",
    "DATA_TEST_PATH = DRIVE_PATH / 'mnist_test.csv'\n",
    "MODEL_PATH = DRIVE_PATH / 'model_final_CNN.pth'\n",
    "HYPERPARAMS_PATH = DRIVE_PATH / 'best_hyperparams_CNN.json'\n",
    "GRAPH_DIR = DRIVE_PATH / 'graphs'\n",
    "\n",
    "# Cr√©er le dossier graphs s'il n'existe pas\n",
    "GRAPH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e avec succ√®s\")\n",
    "print(f\"üìÅ R√©pertoire de travail : {DRIVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6c354",
   "metadata": {},
   "source": [
    "# üìä CELLULE 2 : Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c564fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                         CHARGEMENT DES DONN√âES                           ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Dataset MNIST : 60,000 images d'entra√Ænement + 10,000 images de test\n",
    "Format : Images 28√ó28 pixels en niveaux de gris (0-255)\n",
    "Classes : 10 chiffres (0 √† 9)\n",
    "\"\"\"\n",
    "\n",
    "def load_mnist_data_cnn(train_path, test_path, train_split=0.8, shuffle=True):\n",
    "    \"\"\"\n",
    "    Charge et pr√©pare les donn√©es MNIST pour un CNN.\n",
    "    \n",
    "    Le CNN n√©cessite des donn√©es au format : (batch, channels, height, width)\n",
    "    Pour MNIST : (N, 1, 28, 28) o√π N = nombre d'exemples\n",
    "    \n",
    "    Args:\n",
    "        train_path (str|Path): Chemin vers mnist_train.csv\n",
    "        test_path (str|Path): Chemin vers mnist_test.csv\n",
    "        train_split (float): Proportion pour le training set (le reste = dev set)\n",
    "        shuffle (bool): M√©langer les donn√©es avant le split\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X_train, Y_train, X_dev, Y_dev, X_test, Y_test)\n",
    "               - X : Tensors de shape (N, 1, 28, 28), normalis√©s [0, 1]\n",
    "               - Y : Tensors de labels (N,) de type long\n",
    "    \n",
    "    Example:\n",
    "        >>> X_train, Y_train, X_dev, Y_dev, X_test, Y_test = load_mnist_data_cnn(\n",
    "        ...     'mnist_train.csv', 'mnist_test.csv'\n",
    "        ... )\n",
    "        >>> print(X_train.shape)  # torch.Size([48000, 1, 28, 28])\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä CHARGEMENT DES DONN√âES MNIST POUR CNN\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 1 : Charger les fichiers CSV\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Chargement des fichiers CSV...\")\n",
    "    data_train_full = pd.read_csv(train_path).values\n",
    "    data_test_full = pd.read_csv(test_path).values\n",
    "    \n",
    "    print(f\"   ‚úì Train brut : {data_train_full.shape[0]:,} exemples\")\n",
    "    print(f\"   ‚úì Test : {data_test_full.shape[0]:,} exemples\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 2 : M√©langer les donn√©es (optionnel)\n",
    "    # ========================================================================\n",
    "    \n",
    "    if shuffle:\n",
    "        print(\"\\nüîÄ M√©lange des donn√©es d'entra√Ænement...\")\n",
    "        np.random.shuffle(data_train_full)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 3 : Split Train/Dev\n",
    "    # ========================================================================\n",
    "    \n",
    "    split_idx = int(train_split * len(data_train_full))\n",
    "    data_train = data_train_full[:split_idx]\n",
    "    data_dev = data_train_full[split_idx:]\n",
    "    \n",
    "    print(f\"\\nüìÇ Split {int(train_split*100)}/{int((1-train_split)*100)} :\")\n",
    "    print(f\"   ‚úì Train : {len(data_train):,} exemples\")\n",
    "    print(f\"   ‚úì Dev : {len(data_dev):,} exemples\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 4 : Pr√©parer les tenseurs pour CNN\n",
    "    # ========================================================================\n",
    "    \n",
    "    def prepare_cnn_data(data):\n",
    "        \"\"\"\n",
    "        Convertit donn√©es brutes en tensors PyTorch format CNN.\n",
    "        \n",
    "        Transformations :\n",
    "        1. Extraire labels (derni√®re colonne)\n",
    "        2. Extraire pixels (toutes les colonnes sauf derni√®re)\n",
    "        3. Normaliser pixels : [0, 255] ‚Üí [0, 1]\n",
    "        4. Reshape : (N, 784) ‚Üí (N, 1, 28, 28)\n",
    "        5. Envoyer sur GPU/CPU\n",
    "        \"\"\"\n",
    "        # Labels\n",
    "        labels = torch.tensor(data[:, -1], dtype=torch.long)\n",
    "        \n",
    "        # Images : reshape (N, 784) ‚Üí (N, 1, 28, 28)\n",
    "        images = torch.tensor(data[:, :-1], dtype=torch.float32)\n",
    "        images = images.reshape(-1, 1, 28, 28)\n",
    "        \n",
    "        # Normalisation [0, 255] ‚Üí [0, 1]\n",
    "        images = images / 255.0\n",
    "        \n",
    "        return images.to(device), labels.to(device)\n",
    "    \n",
    "    print(\"\\n‚öôÔ∏è  Conversion en tensors PyTorch...\")\n",
    "    X_train, Y_train = prepare_cnn_data(data_train)\n",
    "    X_dev, Y_dev = prepare_cnn_data(data_dev)\n",
    "    X_test, Y_test = prepare_cnn_data(data_test_full)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 5 : R√©sum√© final\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ DONN√âES CHARG√âES ET PR√äTES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Dataset':<10} {'Shape':<25} {'Device':<10} {'Dtype'}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'X_train':<10} {str(tuple(X_train.shape)):<25} {str(X_train.device):<10} {X_train.dtype}\")\n",
    "    print(f\"{'Y_train':<10} {str(tuple(Y_train.shape)):<25} {str(Y_train.device):<10} {Y_train.dtype}\")\n",
    "    print(f\"{'X_dev':<10} {str(tuple(X_dev.shape)):<25} {str(X_dev.device):<10} {X_dev.dtype}\")\n",
    "    print(f\"{'Y_dev':<10} {str(tuple(Y_dev.shape)):<25} {str(Y_dev.device):<10} {Y_dev.dtype}\")\n",
    "    print(f\"{'X_test':<10} {str(tuple(X_test.shape)):<25} {str(X_test.device):<10} {X_test.dtype}\")\n",
    "    print(f\"{'Y_test':<10} {str(tuple(Y_test.shape)):<25} {str(Y_test.device):<10} {Y_test.dtype}\")\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev, X_test, Y_test\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EX√âCUTION\n",
    "# ============================================================================\n",
    "\n",
    "X_train, Y_train, X_dev, Y_dev, X_test, Y_test = load_mnist_data_cnn(\n",
    "    DATA_TRAIN_PATH, \n",
    "    DATA_TEST_PATH,\n",
    "    train_split=0.8,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82131e",
   "metadata": {},
   "source": [
    "# üèóÔ∏è CELLULE 3 : Architecture CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                      D√âFINITION DU MOD√àLE CNN                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Architecture flexible :\n",
    "- Nombre variable de couches convolutionnelles\n",
    "- Nombre variable de couches fully connected\n",
    "- Support de Batch Normalization, Dropout, et diff√©rentes activations\n",
    "\"\"\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    R√©seau de Neurones Convolutionnel (CNN) flexible pour MNIST.\n",
    "    \n",
    "    Architecture :\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ  INPUT (1, 28, 28)                                          ‚îÇ\n",
    "    ‚îÇ     ‚Üì                                                       ‚îÇ\n",
    "    ‚îÇ  [Conv2D ‚Üí (BatchNorm) ‚Üí Activation ‚Üí MaxPool ‚Üí Dropout]    ‚îÇ  √ó n couches\n",
    "    ‚îÇ     ‚Üì                                                       ‚îÇ\n",
    "    ‚îÇ  Flatten                                                    ‚îÇ\n",
    "    ‚îÇ     ‚Üì                                                       ‚îÇ\n",
    "    ‚îÇ  [Linear ‚Üí (BatchNorm) ‚Üí Activation ‚Üí Dropout]              ‚îÇ  √ó n couches\n",
    "    ‚îÇ     ‚Üì                                                       ‚îÇ\n",
    "    ‚îÇ  Linear(10) ‚Üí OUTPUT (logits)                               ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    \n",
    "    Args:\n",
    "        conv_channels (list): Nombre de filtres par couche conv. Ex: [32, 64, 128]\n",
    "        fc_sizes (list): Taille des couches fully connected. Ex: [128, 64]\n",
    "        kernel_size (int): Taille des kernels convolutionnels (3 ou 5)\n",
    "        pool_size (int): Taille du max pooling (typiquement 2)\n",
    "        dropout (float): Taux de dropout (0.0 √† 1.0)\n",
    "        batch_norm (bool): Utiliser Batch Normalization\n",
    "        activation (str): Type d'activation ('relu', 'leaky_relu', 'gelu')\n",
    "    \n",
    "    Example:\n",
    "        >>> model = CNN(\n",
    "        ...     conv_channels=[64, 64],\n",
    "        ...     fc_sizes=[160],\n",
    "        ...     kernel_size=5,\n",
    "        ...     dropout=0.5,\n",
    "        ...     batch_norm=False,\n",
    "        ...     activation='gelu'\n",
    "        ... )\n",
    "        >>> print(model)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, conv_channels=[32, 64], fc_sizes=[128],\n",
    "                 kernel_size=3, pool_size=2, dropout=0.5,\n",
    "                 batch_norm=True, activation='relu'):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CONFIGURATION\n",
    "        # ====================================================================\n",
    "        \n",
    "        self.use_batch_norm = batch_norm\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_batch_norms = nn.ModuleList() if batch_norm else None\n",
    "        \n",
    "        # ====================================================================\n",
    "        # FONCTION D'ACTIVATION\n",
    "        # ====================================================================\n",
    "        \n",
    "        activation_functions = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.1),\n",
    "            'gelu': nn.GELU()\n",
    "        }\n",
    "        self.activation = activation_functions.get(activation, nn.ReLU())\n",
    "        \n",
    "        # ====================================================================\n",
    "        # COUCHES CONVOLUTIONNELLES\n",
    "        # ====================================================================\n",
    "        \n",
    "        in_channels = 1  # MNIST = 1 canal (grayscale)\n",
    "        \n",
    "        for out_channels in conv_channels:\n",
    "            # Conv2D avec padding=1 pour pr√©server la taille\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv2d(in_channels, out_channels, \n",
    "                         kernel_size=kernel_size, padding=1)\n",
    "            )\n",
    "            \n",
    "            if batch_norm:\n",
    "                self.conv_batch_norms.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Pooling et Dropout\n",
    "        self.pool = nn.MaxPool2d(pool_size, pool_size)\n",
    "        self.dropout_conv = nn.Dropout2d(dropout * 0.5)  # Dropout r√©duit pour conv\n",
    "        self.dropout_fc = nn.Dropout(dropout)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CALCUL AUTOMATIQUE DE LA TAILLE APR√àS CONVOLUTIONS\n",
    "        # ====================================================================\n",
    "        \n",
    "        flatten_size = self._get_flatten_size(conv_channels, kernel_size, pool_size)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # COUCHES FULLY CONNECTED\n",
    "        # ====================================================================\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.fc_batch_norms = nn.ModuleList() if batch_norm else None\n",
    "        \n",
    "        in_features = flatten_size\n",
    "        for fc_size in fc_sizes:\n",
    "            self.fc_layers.append(nn.Linear(in_features, fc_size))\n",
    "            \n",
    "            if batch_norm:\n",
    "                self.fc_batch_norms.append(nn.BatchNorm1d(fc_size))\n",
    "            \n",
    "            in_features = fc_size\n",
    "        \n",
    "        # Couche de sortie (10 classes)\n",
    "        self.output_layer = nn.Linear(in_features, 10)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # INITIALISATION DES POIDS\n",
    "        # ====================================================================\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    \n",
    "    def _get_flatten_size(self, conv_channels, kernel_size, pool_size):\n",
    "        \"\"\"\n",
    "        Calcule automatiquement la taille du vecteur apr√®s convolutions.\n",
    "        \n",
    "        Utilise un forward pass \"dummy\" avec une image fictive pour d√©terminer\n",
    "        la dimension exacte du vecteur aplati.\n",
    "        \n",
    "        Returns:\n",
    "            int: Nombre d'√©l√©ments dans le vecteur aplati\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Cr√©er une image fictive (batch=1, channels=1, H=28, W=28)\n",
    "            x = torch.zeros(1, 1, 28, 28)\n",
    "            \n",
    "            # Passer √† travers les conv layers\n",
    "            for i in range(len(conv_channels)):\n",
    "                x = self.conv_layers[i](x)\n",
    "                if self.use_batch_norm:\n",
    "                    x = self.conv_batch_norms[i](x)\n",
    "                x = self.activation(x)\n",
    "                x = self.pool(x)\n",
    "            \n",
    "            # Retourner le nombre total d'√©l√©ments\n",
    "            return int(np.prod(x.size()[1:]))\n",
    "    \n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initialise les poids avec la m√©thode de Kaiming He (pour ReLU).\n",
    "        \n",
    "        Am√©liore la convergence en √©vitant les gradients qui explosent/disparaissent.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass du CNN.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Images de shape (batch_size, 1, 28, 28)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Logits de shape (batch_size, 10)\n",
    "        \"\"\"\n",
    "        \n",
    "        # ====================================================================\n",
    "        # BLOC CONVOLUTIONNEL\n",
    "        # ====================================================================\n",
    "        \n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            x = conv(x)\n",
    "            \n",
    "            if self.use_batch_norm:\n",
    "                x = self.conv_batch_norms[i](x)\n",
    "            \n",
    "            x = self.activation(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout_conv(x)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # APLATIR\n",
    "        # ====================================================================\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # (batch, channels, H, W) ‚Üí (batch, flatten_size)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # BLOC FULLY CONNECTED\n",
    "        # ====================================================================\n",
    "        \n",
    "        for i, fc in enumerate(self.fc_layers):\n",
    "            x = fc(x)\n",
    "            \n",
    "            if self.use_batch_norm:\n",
    "                x = self.fc_batch_norms[i](x)\n",
    "            \n",
    "            x = self.activation(x)\n",
    "            x = self.dropout_fc(x)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # SORTIE\n",
    "        # ====================================================================\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(model, X, Y, batch_size=256):\n",
    "    \"\"\"\n",
    "    √âvalue l'accuracy du mod√®le sur un dataset.\n",
    "    \n",
    "    Effectue l'√©valuation par batches pour g√©rer les grands datasets.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Mod√®le √† √©valuer\n",
    "        X (Tensor): Images\n",
    "        Y (Tensor): Labels\n",
    "        batch_size (int): Taille des batches\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy (entre 0 et 1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batch_X = X[i:i+batch_size]\n",
    "            batch_Y = Y[i:i+batch_size]\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == batch_Y).sum().item()\n",
    "            total += batch_Y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "\n",
    "print(\"‚úÖ Architecture CNN d√©finie avec calcul automatique des dimensions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573d059",
   "metadata": {},
   "source": [
    "# üîç CELLULE 4 : Optimisation Bay√©sienne des Hyperparam√®tres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë              OPTIMISATION BAY√âSIENNE AVEC OPTUNA                         ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Objectif : Trouver automatiquement les meilleurs hyperparam√®tres du CNN\n",
    "\n",
    "Hyperparam√®tres optimis√©s :\n",
    "- Architecture : nombre et taille des couches conv/fc\n",
    "- Kernel size : 3√ó3 ou 5√ó5\n",
    "- Dropout : taux de r√©gularisation\n",
    "- Learning rate : vitesse d'apprentissage\n",
    "- L2 regularization : p√©nalit√© sur les poids\n",
    "- Batch normalization : on/off\n",
    "- Fonction d'activation : ReLU/LeakyReLU/GELU\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üî¨ OPTIMISATION BAY√âSIENNE CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION D'ENTRA√éNEMENT POUR OPTUNA\n",
    "# ============================================================================\n",
    "\n",
    "def train_cnn(X, Y, model, optimizer, criterion, epochs=10, batch_size=128, grad_clip=None):\n",
    "    \"\"\"\n",
    "    Entra√Æne le CNN par mini-batches avec gradient clipping optionnel.\n",
    "    \n",
    "    Args:\n",
    "        X (Tensor): Images d'entra√Ænement (N, 1, 28, 28)\n",
    "        Y (Tensor): Labels (N,)\n",
    "        model (nn.Module): Mod√®le CNN √† entra√Æner\n",
    "        optimizer (torch.optim): Optimiseur (AdamW, SGD, etc.)\n",
    "        criterion (nn.Module): Fonction de perte (CrossEntropyLoss)\n",
    "        epochs (int): Nombre d'epochs\n",
    "        batch_size (int): Taille des batches\n",
    "        grad_clip (float|None): Valeur max pour gradient clipping\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: Mod√®le entra√Æn√©\n",
    "    \n",
    "    Notes:\n",
    "        - Shuffle automatique des donn√©es √† chaque epoch\n",
    "        - Gradient clipping pour stabiliser l'entra√Ænement\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # M√©langer les indices √† chaque epoch\n",
    "        indices = torch.randperm(X.size(0))\n",
    "        \n",
    "        # Entra√Ænement par batches\n",
    "        for i in range(0, X.size(0), batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            batch_X = X[batch_indices]\n",
    "            batch_Y = Y[batch_indices]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_Y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (√©vite l'explosion des gradients)\n",
    "            if grad_clip:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            \n",
    "            # Mise √† jour des poids\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION OBJECTIF POUR OPTUNA\n",
    "# ============================================================================\n",
    "\n",
    "def cnn_objective(trial):\n",
    "    \"\"\"\n",
    "    Fonction objectif pour Optuna : teste une configuration d'hyperparam√®tres.\n",
    "    \n",
    "    Optuna va appeler cette fonction plusieurs fois avec diff√©rentes combinaisons\n",
    "    d'hyperparam√®tres pour trouver la meilleure configuration.\n",
    "    \n",
    "    Args:\n",
    "        trial (optuna.Trial): Object trial contenant les suggestions d'hyperparam√®tres\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy sur le dev set (m√©trique √† maximiser)\n",
    "    \n",
    "    Raises:\n",
    "        optuna.TrialPruned: Si l'architecture est invalide ou les r√©sultats m√©diocres\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 1 : SUGG√âRER LES HYPERPARAM√àTRES\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Architecture convolutionnelle\n",
    "    n_conv_layers = trial.suggest_int('n_conv_layers', 2, 3)\n",
    "    conv_channels = [\n",
    "        trial.suggest_categorical(f'conv_ch_{i}', [32, 64, 128, 256])\n",
    "        for i in range(n_conv_layers)\n",
    "    ]\n",
    "    \n",
    "    # Architecture fully connected\n",
    "    n_fc_layers = trial.suggest_int('n_fc_layers', 1, 2)\n",
    "    fc_sizes = [\n",
    "        trial.suggest_int(f'fc_size_{i}', 64, 256, step=32)\n",
    "        for i in range(n_fc_layers)\n",
    "    ]\n",
    "    \n",
    "    # Hyperparam√®tres d'entra√Ænement\n",
    "    kernel_size = trial.suggest_categorical('kernel_size', [3, 5])\n",
    "    dropout = trial.suggest_float('dropout', 0.3, 0.6)\n",
    "    lr = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    l2_lambda = trial.suggest_float('l2_lambda', 1e-5, 1e-3, log=True)\n",
    "    batch_norm = trial.suggest_categorical('batch_norm', [True, False])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'leaky_relu', 'gelu'])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 2 : VALIDATION DE L'ARCHITECTURE\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Calculer la taille de l'image apr√®s n_conv_layers\n",
    "    # Chaque MaxPool2d(2, 2) divise par 2 : 28 ‚Üí 14 ‚Üí 7 ‚Üí 3\n",
    "    image_size = 28\n",
    "    for _ in range(n_conv_layers):\n",
    "        image_size = image_size // 2\n",
    "    \n",
    "    # V√©rifier que le kernel n'est pas trop grand\n",
    "    if kernel_size == 5 and image_size < 5:\n",
    "        raise optuna.TrialPruned(\n",
    "            f\"‚ö†Ô∏è  Kernel {kernel_size}√ó{kernel_size} trop grand pour image {image_size}√ó{image_size}\"\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 3 : CR√âER LE MOD√àLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    try:\n",
    "        model = CNN(\n",
    "            conv_channels=conv_channels,\n",
    "            fc_sizes=fc_sizes,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,\n",
    "            batch_norm=batch_norm,\n",
    "            activation=activation\n",
    "        ).to(device)\n",
    "    except RuntimeError as e:\n",
    "        # Pruner si erreur de dimension\n",
    "        raise optuna.TrialPruned(f\"‚ùå Erreur architecture : {e}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 4 : ENTRA√éNER LE MOD√àLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    \n",
    "    model = train_cnn(\n",
    "        X_train, Y_train, model, optimizer, criterion,\n",
    "        epochs=15, batch_size=128, grad_clip=1.0\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # √âTAPE 5 : √âVALUER SUR DEV SET\n",
    "    # ========================================================================\n",
    "    \n",
    "    accuracy = evaluate_model(model, X_dev, Y_dev)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LANCER L'OPTIMISATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüöÄ Lancement de l'optimisation (50 trials, timeout 1h)...\")\n",
    "print(\"   Chaque trial teste une configuration d'hyperparam√®tres diff√©rente\\n\")\n",
    "\n",
    "# Cr√©er l'√©tude Optuna\n",
    "study_cnn = optuna.create_study(\n",
    "    direction='maximize',  # Maximiser l'accuracy\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED),  # Algorithme bay√©sien\n",
    "    pruner=optuna.pruners.MedianPruner()  # Arr√™te les trials peu prometteurs\n",
    ")\n",
    "\n",
    "# Optimiser\n",
    "study_cnn.optimize(\n",
    "    cnn_objective, \n",
    "    n_trials=50,  # Nombre de configurations √† tester\n",
    "    timeout=3600,  # Arr√™t apr√®s 1h max\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# R√âSULTATS DE L'OPTIMISATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ R√âSULTATS DE L'OPTIMISATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleure accuracy : {study_cnn.best_value:.4f}\")\n",
    "print(f\"\\nüìã Meilleurs hyperparam√®tres :\")\n",
    "for key, value in study_cnn.best_params.items():\n",
    "    print(f\"   ‚Ä¢ {key:<20} : {value}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDER LES HYPERPARAM√àTRES\n",
    "# ============================================================================\n",
    "\n",
    "# Reconstruire le dictionnaire complet\n",
    "best_params = study_cnn.best_params\n",
    "n_conv = best_params['n_conv_layers']\n",
    "n_fc = best_params['n_fc_layers']\n",
    "\n",
    "hyperparams_to_save = {\n",
    "    'n_conv_layers': n_conv,\n",
    "    'conv_channels': [best_params[f'conv_ch_{i}'] for i in range(n_conv)],\n",
    "    'n_fc_layers': n_fc,\n",
    "    'fc_sizes': [best_params[f'fc_size_{i}'] for i in range(n_fc)],\n",
    "    'kernel_size': best_params['kernel_size'],\n",
    "    'dropout': best_params['dropout'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'l2_lambda': best_params['l2_lambda'],\n",
    "    'batch_norm': best_params['batch_norm'],\n",
    "    'activation': best_params['activation'],\n",
    "    'best_dev_accuracy': study_cnn.best_value\n",
    "}\n",
    "\n",
    "with open(HYPERPARAMS_PATH, 'w') as f:\n",
    "    json.dump(hyperparams_to_save, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Hyperparam√®tres sauvegard√©s dans : {HYPERPARAMS_PATH}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISATION DES R√âSULTATS D'OPTIMISATION\n",
    "# ============================================================================\n",
    "\n",
    "# Graphique 1 : Historique d'optimisation\n",
    "fig1 = plot_optimization_history(study_cnn)\n",
    "fig1.update_layout(\n",
    "    title=\"Historique d'Optimisation Bay√©sienne\",\n",
    "    xaxis_title=\"Trial\",\n",
    "    yaxis_title=\"Dev Accuracy\"\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# Graphique 2 : Importance des hyperparam√®tres\n",
    "fig2 = plot_param_importances(study_cnn)\n",
    "fig2.update_layout(\n",
    "    title=\"Importance des Hyperparam√®tres\"\n",
    ")\n",
    "fig2.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ OPTIMISATION TERMIN√âE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd6559",
   "metadata": {},
   "source": [
    "# üéØ CELLULE 5 : Entra√Ænement Final avec Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                  ENTRA√éNEMENT FINAL DU MOD√àLE                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Utilise les meilleurs hyperparam√®tres trouv√©s par Optuna\n",
    "Impl√©mente l'early stopping pour √©viter le surapprentissage\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LES MEILLEURS HYPERPARAM√àTRES\n",
    "# ============================================================================\n",
    "\n",
    "with open(HYPERPARAMS_PATH, 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚öôÔ∏è  HYPERPARAM√àTRES CHARG√âS\")\n",
    "print(\"=\"*70)\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION D'ENTRA√éNEMENT AVEC EARLY STOPPING\n",
    "# ============================================================================\n",
    "\n",
    "def train_cnn_with_early_stopping(X_train, Y_train, X_val, Y_val, hyperparams,\n",
    "                                   patience=5, max_epochs=100, batch_size=128):\n",
    "    \"\"\"\n",
    "    Entra√Æne le CNN avec early stopping et learning rate scheduling.\n",
    "    \n",
    "    Early Stopping : Arr√™te l'entra√Ænement si la val accuracy ne s'am√©liore pas\n",
    "    pendant 'patience' √©valuations cons√©cutives.\n",
    "    \n",
    "    Args:\n",
    "        X_train, Y_train (Tensor): Donn√©es d'entra√Ænement\n",
    "        X_val, Y_val (Tensor): Donn√©es de validation\n",
    "        hyperparams (dict): Hyperparam√®tres du mod√®le\n",
    "        patience (int): Nombre d'epochs sans am√©lioration avant arr√™t\n",
    "        max_epochs (int): Nombre maximum d'epochs\n",
    "        batch_size (int): Taille des batches\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model_final, best_val_acc, history)\n",
    "            - model_final : Mod√®le avec les meilleurs poids\n",
    "            - best_val_acc : Meilleure accuracy sur validation\n",
    "            - history : Dictionnaire avec historique d'entra√Ænement\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # INITIALISATION DU MOD√àLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    model = CNN(\n",
    "        conv_channels=hyperparams['conv_channels'],\n",
    "        fc_sizes=hyperparams['fc_sizes'],\n",
    "        kernel_size=hyperparams['kernel_size'],\n",
    "        dropout=hyperparams['dropout'],\n",
    "        batch_norm=hyperparams['batch_norm'],\n",
    "        activation=hyperparams['activation']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Crit√®re de perte et optimiseur\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=hyperparams['learning_rate'],\n",
    "        weight_decay=hyperparams['l2_lambda']\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler : r√©duit le LR si plateau\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # INITIALISATION DE L'HISTORIQUE\n",
    "    # ========================================================================\n",
    "    \n",
    "    history = {\n",
    "        'epochs': [],\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_accs': [],\n",
    "        'val_accs': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BOUCLE D'ENTRA√éNEMENT\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ D√âMARRAGE DE L'ENTRA√éNEMENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Shuffle des donn√©es\n",
    "        indices = torch.randperm(X_train.size(0))\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        # Entra√Ænement par batches\n",
    "        for i in range(0, X_train.size(0), batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            batch_X = X_train[batch_indices]\n",
    "            batch_Y = Y_train[batch_indices]\n",
    "            \n",
    "            # Forward + backward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_Y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # VALIDATION (tous les 2 epochs)\n",
    "        # ====================================================================\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # √âvaluer train accuracy\n",
    "                train_acc = evaluate_model(model, X_train, Y_train, batch_size)\n",
    "                train_loss = epoch_loss / (X_train.size(0) // batch_size)\n",
    "                \n",
    "                # √âvaluer validation\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss = criterion(val_outputs, Y_val).item()\n",
    "                val_acc = evaluate_model(model, X_val, Y_val, batch_size)\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # Sauvegarder l'historique\n",
    "            history['epochs'].append(epoch)\n",
    "            history['train_losses'].append(train_loss)\n",
    "            history['val_losses'].append(val_loss)\n",
    "            history['train_accs'].append(train_acc)\n",
    "            history['val_accs'].append(val_acc)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Affichage p√©riodique\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch:3d} | \"\n",
    "                      f\"Train: Acc={train_acc:.4f} Loss={train_loss:.4f} | \"\n",
    "                      f\"Val: Acc={val_acc:.4f} Loss={val_loss:.4f}\")\n",
    "            \n",
    "            # Arr√™t si pas d'am√©lioration\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚úì Early stopping √† l'epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CHARGER LES MEILLEURS POIDS\n",
    "    # ========================================================================\n",
    "    \n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # VISUALISATION DE L'ENTRA√éNEMENT\n",
    "    # ========================================================================\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Axe 1 : Accuracy\n",
    "    ax1.plot(history['epochs'], history['train_accs'], \n",
    "             label='Train Accuracy', linewidth=2.5, color='#4ECDC4', marker='o')\n",
    "    ax1.plot(history['epochs'], history['val_accs'], \n",
    "             label='Val Accuracy', linewidth=2.5, linestyle='--', \n",
    "             color='#45B7D1', marker='s')\n",
    "    ax1.set_xlabel('Epochs', fontsize=13, fontweight='bold')\n",
    "    ax1.set_ylabel('Accuracy', color='tab:blue', fontsize=13, fontweight='bold')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax1.legend(loc='lower right', fontsize=11)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Axe 2 : Loss\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(history['epochs'], history['train_losses'], \n",
    "             label='Train Loss', linewidth=2.5, linestyle='-', \n",
    "             color='#FF6B6B', marker='o', alpha=0.7)\n",
    "    ax2.plot(history['epochs'], history['val_losses'], \n",
    "             label='Val Loss', linewidth=2.5, linestyle='--', \n",
    "             color='#EE5A6F', marker='s', alpha=0.7)\n",
    "    ax2.set_ylabel('Loss', color='tab:red', fontsize=13, fontweight='bold')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax2.legend(loc='upper right', fontsize=11)\n",
    "    \n",
    "    max_loss = max(max(history['train_losses']), max(history['val_losses']))\n",
    "    ax2.set_ylim(0, min(max_loss * 1.1, 3.0))\n",
    "    \n",
    "    plt.title('CNN Training History', fontsize=16, pad=20, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(GRAPH_DIR / 'cnn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return model, best_val_acc, history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENTRA√éNER LE MOD√àLE FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ ENTRA√éNEMENT FINAL DU CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_final, final_val_acc, history = train_cnn_with_early_stopping(\n",
    "    X_train, Y_train, X_dev, Y_dev, best_params, \n",
    "    patience=5, max_epochs=100, batch_size=128\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDER LE MOD√àLE\n",
    "# ============================================================================\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_final.state_dict(),\n",
    "    'hyperparams': best_params,\n",
    "    'val_accuracy': final_val_acc,\n",
    "    'train_history': history\n",
    "}, MODEL_PATH)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ MOD√àLE CNN SAUVEGARD√â\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìÅ Fichier : {MODEL_PATH}\")\n",
    "print(f\"üéØ Val Accuracy : {final_val_acc:.4f}\")\n",
    "print(f\"üìä Historique : {len(history['epochs'])} epochs enregistr√©s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08543b09",
   "metadata": {},
   "source": [
    "# üìä CELLULE 6 : √âvaluation sur le Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    √âVALUATION SUR LE TEST SET                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "√âvaluation finale du mod√®le sur des donn√©es jamais vues pendant l'entra√Ænement\n",
    "M√©triques : Accuracy, AUC-ROC, Confusion Matrix, Classification Report\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä √âVALUATION CNN SUR TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LE MOD√àLE SAUVEGARD√â\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÑ Chargement du mod√®le...\")\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "best_params = checkpoint['hyperparams']\n",
    "\n",
    "model_final = CNN(\n",
    "    conv_channels=best_params['conv_channels'],\n",
    "    fc_sizes=best_params['fc_sizes'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout=best_params['dropout'],\n",
    "    batch_norm=best_params['batch_norm'],\n",
    "    activation=best_params['activation']\n",
    ").to(device)\n",
    "\n",
    "model_final.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"‚úÖ Mod√®le charg√©\")\n",
    "print(f\"   Architecture Conv : {best_params['conv_channels']}\")\n",
    "print(f\"   Architecture FC : {best_params['fc_sizes']}\")\n",
    "print(f\"   Val Accuracy : {checkpoint['val_accuracy']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PR√âDICTIONS SUR LE TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÑ G√©n√©ration des pr√©dictions...\")\n",
    "\n",
    "model_final.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model_final(X_test)\n",
    "    test_probs = torch.softmax(test_outputs, dim=1)\n",
    "    _, test_pred = torch.max(test_outputs, 1)\n",
    "    \n",
    "    # Convertir en numpy pour les m√©triques sklearn\n",
    "    y_true = Y_test.cpu().numpy()\n",
    "    y_pred = test_pred.cpu().numpy()\n",
    "    y_probs = test_probs.cpu().numpy()\n",
    "    \n",
    "    # Calculer les m√©triques\n",
    "    test_acc = (test_pred == Y_test).float().mean().item()\n",
    "    auc_score = roc_auc_score(y_true, y_probs, multi_class='ovr', average='macro')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = criterion(test_outputs, Y_test).item()\n",
    "\n",
    "# ============================================================================\n",
    "# AFFICHAGE DES R√âSULTATS GLOBAUX\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ R√âSULTATS SUR LE TEST SET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'M√©trique':<25} {'Valeur':<15} {'Interpr√©tation'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Test Accuracy':<25} {test_acc:<15.4f} {'ü•á Excellent' if test_acc > 0.99 else 'ü•à Tr√®s bon' if test_acc > 0.98 else 'ü•â Bon'}\")\n",
    "print(f\"{'AUC-ROC (macro)':<25} {auc_score:<15.4f} {'ü•á Excellent' if auc_score > 0.99 else 'ü•à Tr√®s bon' if auc_score > 0.98 else 'ü•â Bon'}\")\n",
    "print(f\"{'Test Loss':<25} {test_loss:<15.4f} {'‚úÖ Faible' if test_loss < 0.1 else '‚ö†Ô∏è  Mod√©r√©'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CLASSIFICATION REPORT D√âTAILL√â\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã CLASSIFICATION REPORT (par classe)\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_true, y_pred, digits=4, target_names=[str(i) for i in range(10)]))\n",
    "\n",
    "# ============================================================================\n",
    "# MATRICE DE CONFUSION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä G√©n√©ration de la matrice de confusion...\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "# Titre et colorbar\n",
    "plt.title('Matrice de Confusion - CNN Test Set', fontsize=16, pad=20, fontweight='bold')\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Nombre de pr√©dictions', fontsize=12)\n",
    "\n",
    "# Ticks\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, range(10), fontsize=11)\n",
    "plt.yticks(tick_marks, range(10), fontsize=11)\n",
    "plt.xlabel('Pr√©diction', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('V√©rit√© Terrain', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Annotations\n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        value = cm[i, j]\n",
    "        \n",
    "        # Surligner en rouge les erreurs importantes (> 10)\n",
    "        if i != j and value > 10:\n",
    "            rect = mpatches.Rectangle(\n",
    "                (j-0.4, i-0.4), 0.8, 0.8,\n",
    "                fill=True, facecolor='red',\n",
    "                alpha=0.25, edgecolor='darkred', linewidth=2.5\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        # Couleur du texte (blanc si fond sombre, noir sinon)\n",
    "        text_color = 'white' if value > thresh else 'black'\n",
    "        font_weight = 'bold' if (i != j and value > 10) else 'normal'\n",
    "        \n",
    "        plt.text(j, i, value, ha='center', va='center',\n",
    "                color=text_color, fontsize=11, weight=font_weight)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# ACCURACY PAR CLASSE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä ACCURACY PAR CLASSE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class_accs = []\n",
    "print(f\"\\n{'Chiffre':<10} {'Accuracy':<12} {'Nb Exemples':<15} {'Qualit√©'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for digit in range(10):\n",
    "    mask = (Y_test == digit)\n",
    "    if mask.sum() > 0:\n",
    "        digit_acc = (test_pred[mask] == Y_test[mask]).float().mean().item()\n",
    "        n_examples = mask.sum().item()\n",
    "        class_accs.append(digit_acc)\n",
    "        \n",
    "        quality = \"ü•á\" if digit_acc > 0.99 else \"ü•à\" if digit_acc > 0.98 else \"ü•â\" if digit_acc > 0.97 else \"‚ö†Ô∏è\"\n",
    "        \n",
    "        print(f\"{digit:<10} {digit_acc:<12.4f} {n_examples:<15} {quality}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Moyenne':<10} {np.mean(class_accs):<12.4f}\")\n",
    "print(f\"{'√âcart-type':<10} {np.std(class_accs):<12.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# IDENTIFIER LES CLASSES PROBL√âMATIQUES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç ANALYSE DES CONFUSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Trouver les paires de chiffres les plus confondues\n",
    "confusions = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 5:  # Au moins 5 erreurs\n",
    "            confusions.append((i, j, cm[i, j]))\n",
    "\n",
    "confusions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(f\"\\nüî¥ Top 5 des confusions (Vrai ‚Üí Pr√©dit) :\")\n",
    "for i, (true_class, pred_class, count) in enumerate(confusions[:5], 1):\n",
    "    percentage = (count / cm[true_class].sum()) * 100\n",
    "    print(f\"   {i}. Chiffre {true_class} ‚Üí {pred_class} : {count} erreurs ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ √âVALUATION TERMIN√âE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887ebf7",
   "metadata": {},
   "source": [
    "# üé® CELLULE 7 : Visualisation des Filtres et Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë              VISUALISATION DES FILTRES CONVOLUTIONNELS                   ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Objectif : Comprendre ce que le CNN a appris √† d√©tecter\n",
    "\n",
    "1. Filtres (kernels) : Motifs que le CNN recherche dans les images\n",
    "2. Feature Maps : Activations produites par ces filtres sur une image\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üé® VISUALISATION DES FILTRES CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# EXTRACTION DES FILTRES DE LA PREMI√àRE COUCHE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÑ Extraction des filtres convolutionnels...\")\n",
    "\n",
    "# Extraire les poids de la premi√®re couche conv\n",
    "first_conv = model_final.conv_layers[0]\n",
    "filters = first_conv.weight.data.cpu().numpy()\n",
    "\n",
    "print(f\"‚úÖ Filtres extraits\")\n",
    "print(f\"   Shape : {filters.shape}\")\n",
    "print(f\"   Nombre de filtres : {filters.shape[0]}\")\n",
    "print(f\"   Taille des filtres : {filters.shape[2]}√ó{filters.shape[3]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISATION DES FILTRES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä G√©n√©ration de la visualisation des filtres...\")\n",
    "\n",
    "n_filters = min(32, filters.shape[0])\n",
    "n_cols = 8\n",
    "n_rows = (n_filters + n_cols - 1) // n_cols  # Arrondi sup√©rieur\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 2.5 * n_rows))\n",
    "fig.suptitle('Filtres Convolutionnels - Premi√®re Couche\\n'\n",
    "             'Ces filtres d√©tectent des patterns de base (bords, coins, textures)', \n",
    "             fontsize=16, y=0.98, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < n_filters:\n",
    "        # Extraire le filtre (canal 0 car images grayscale)\n",
    "        filt = filters[i, 0, :, :]\n",
    "        \n",
    "        # Normaliser pour visualisation [0, 1]\n",
    "        filt_norm = (filt - filt.min()) / (filt.max() - filt.min() + 1e-8)\n",
    "        \n",
    "        # Afficher\n",
    "        im = ax.imshow(filt_norm, cmap='viridis', interpolation='nearest')\n",
    "        ax.set_title(f'Filtre {i}', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Colorbar pour chaque filtre\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_conv_filters.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSE STATISTIQUE DES FILTRES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä Statistiques des filtres :\")\n",
    "print(f\"   Min : {filters.min():.4f}\")\n",
    "print(f\"   Max : {filters.max():.4f}\")\n",
    "print(f\"   Moyenne : {filters.mean():.4f}\")\n",
    "print(f\"   √âcart-type : {filters.std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISATION DES FEATURE MAPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üî¨ VISUALISATION DES FEATURE MAPS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüîÑ G√©n√©ration des feature maps sur un exemple du test set...\")\n",
    "\n",
    "# ============================================================================\n",
    "# S√âLECTIONNER UN EXEMPLE\n",
    "# ============================================================================\n",
    "\n",
    "sample_idx = 0\n",
    "sample_image = X_test[sample_idx:sample_idx+1]\n",
    "sample_label = Y_test[sample_idx].item()\n",
    "\n",
    "# ============================================================================\n",
    "# CAPTURER LES ACTIVATIONS AVEC DES HOOKS\n",
    "# ============================================================================\n",
    "\n",
    "# Dictionnaire pour stocker les activations\n",
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    \"\"\"\n",
    "    Factory function pour cr√©er des hooks.\n",
    "    \n",
    "    Un hook est une fonction callback qui s'ex√©cute automatiquement\n",
    "    apr√®s le forward pass d'une couche.\n",
    "    \n",
    "    Args:\n",
    "        name (str): Nom de la couche pour identifier l'activation\n",
    "    \n",
    "    Returns:\n",
    "        function: Hook function\n",
    "    \"\"\"\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Enregistrer hooks sur toutes les couches convolutionnelles\n",
    "hooks = []\n",
    "for i, layer in enumerate(model_final.conv_layers):\n",
    "    hooks.append(layer.register_forward_hook(get_activation(f'conv{i}')))\n",
    "\n",
    "# Forward pass pour d√©clencher les hooks\n",
    "model_final.eval()\n",
    "with torch.no_grad():\n",
    "    output = model_final(sample_image)\n",
    "    pred = output.argmax().item()\n",
    "\n",
    "# Retirer les hooks (important pour √©viter les fuites m√©moire)\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "print(f\"‚úÖ Activations captur√©es pour {len(activations)} couches\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISER LES FEATURE MAPS DE LA PREMI√àRE COUCHE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä Visualisation des feature maps (Conv Layer 0)...\")\n",
    "\n",
    "feature_maps = activations['conv0'].cpu().numpy()[0]  # Shape: (n_channels, H, W)\n",
    "\n",
    "n_maps = min(16, feature_maps.shape[0])\n",
    "fig, axes = plt.subplots(4, 4, figsize=(14, 14))\n",
    "fig.suptitle(f'Feature Maps - Couche Convolutionnelle 0\\n'\n",
    "             f'Image : Chiffre {sample_label} | Pr√©diction : {pred} | '\n",
    "             f'{\"‚úÖ Correct\" if pred == sample_label else \"‚ùå Erreur\"}',\n",
    "             fontsize=15, y=0.98, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < n_maps:\n",
    "        # Extraire la feature map\n",
    "        fmap = feature_maps[i]\n",
    "        \n",
    "        # Afficher\n",
    "        im = ax.imshow(fmap, cmap='viridis', interpolation='bilinear')\n",
    "        ax.set_title(f'Channel {i}', fontsize=11, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_feature_maps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# AFFICHER L'IMAGE ORIGINALE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüì∏ Image originale :\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "im = ax.imshow(sample_image.cpu().squeeze(), cmap='gray')\n",
    "ax.set_title(f'Image Originale\\n'\n",
    "             f'Vrai Label : {sample_label} | Pr√©diction : {pred}',\n",
    "             fontsize=13, fontweight='bold', pad=15)\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_sample_image.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISER TOUTES LES COUCHES (OPTIONNEL)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä Visualisation de toutes les couches convolutionnelles...\")\n",
    "\n",
    "n_conv_layers = len(activations)\n",
    "fig, axes = plt.subplots(1, n_conv_layers, figsize=(6 * n_conv_layers, 5))\n",
    "\n",
    "if n_conv_layers == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (layer_name, fmaps) in enumerate(activations.items()):\n",
    "    fmaps_np = fmaps.cpu().numpy()[0]\n",
    "    \n",
    "    # Prendre la moyenne sur tous les channels pour visualisation\n",
    "    fmap_mean = fmaps_np.mean(axis=0)\n",
    "    \n",
    "    im = axes[idx].imshow(fmap_mean, cmap='viridis', interpolation='bilinear')\n",
    "    axes[idx].set_title(f'{layer_name.upper()}\\n'\n",
    "                        f'Shape: {fmaps_np.shape}',\n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Activation Moyenne par Couche - Chiffre {sample_label}',\n",
    "             fontsize=15, y=0.98, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_all_layers_activations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ VISUALISATION DES FILTRES TERMIN√âE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72564920",
   "metadata": {},
   "source": [
    "# üó∫Ô∏è CELLULE 8 : R√©duction de Dimensionnalit√© (t-SNE, UMAP, PaCMAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dba548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë          VISUALISATION DES EMBEDDINGS CNN EN 2D                          ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Objectif : Visualiser comment le CNN organise les chiffres dans l'espace latent\n",
    "\n",
    "M√©thodes compar√©es :\n",
    "1. t-SNE : Pr√©serve les voisinages locaux (clusters)\n",
    "2. UMAP : Pr√©serve la topologie globale et locale\n",
    "3. PaCMAP : √âquilibre entre structure locale et globale\n",
    "\n",
    "Les embeddings sont extraits de la derni√®re couche FC (avant la sortie)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üó∫Ô∏è  VISUALISATION t-SNE, UMAP, PaCMAP DES EMBEDDINGS CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# INSTALLER LES PACKAGES N√âCESSAIRES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüì¶ V√©rification des packages de r√©duction de dimensionnalit√©...\")\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "    print(\"   ‚úÖ UMAP install√©\")\n",
    "except ImportError:\n",
    "    print(\"   üì• Installation de UMAP...\")\n",
    "    !pip install umap-learn -q\n",
    "    import umap\n",
    "    print(\"   ‚úÖ UMAP install√© avec succ√®s\")\n",
    "\n",
    "try:\n",
    "    import pacmap\n",
    "    print(\"   ‚úÖ PaCMAP install√©\")\n",
    "except ImportError:\n",
    "    print(\"   üì• Installation de PaCMAP...\")\n",
    "    !pip install pacmap -q\n",
    "    import pacmap\n",
    "    print(\"   ‚úÖ PaCMAP install√© avec succ√®s\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# ============================================================================\n",
    "# EXTRAIRE LES EMBEDDINGS DE LA DERNI√àRE COUCHE FC\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÑ Extraction des embeddings CNN...\")\n",
    "\n",
    "# Dictionnaire pour stocker les activations\n",
    "activations_cnn = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    \"\"\"Hook pour capturer les activations\"\"\"\n",
    "    def hook(model, input, output):\n",
    "        activations_cnn[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Hook sur la derni√®re couche FC (juste avant la sortie)\n",
    "target_layer = model_final.fc_layers[-1]\n",
    "hook_handle = target_layer.register_forward_hook(get_activation('embeddings'))\n",
    "\n",
    "# Forward pass sur tout le test set\n",
    "model_final.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model_final(X_test)\n",
    "\n",
    "# R√©cup√©rer les embeddings\n",
    "embeddings_cnn = activations_cnn['embeddings'].cpu().numpy()\n",
    "y_true = Y_test.cpu().numpy()\n",
    "\n",
    "# Retirer le hook\n",
    "hook_handle.remove()\n",
    "\n",
    "print(f\"‚úÖ Embeddings CNN extraits\")\n",
    "print(f\"   Shape : {embeddings_cnn.shape}\")\n",
    "print(f\"   Dimension des embeddings : {embeddings_cnn.shape[1]}\")\n",
    "print(f\"   Nombre d'exemples : {embeddings_cnn.shape[0]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# APPLIQUER LES 3 M√âTHODES DE R√âDUCTION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ APPLICATION DES R√âDUCTIONS DE DIMENSIONNALIT√â\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚è±Ô∏è  Estimation : 1-2 minutes pour les 3 m√©thodes\\n\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. t-SNE\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"üîÑ [1/3] t-SNE en cours...\")\n",
    "start = time.time()\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    perplexity=30,\n",
    "    max_iter=1000,  # ‚úÖ Correction : max_iter au lieu de n_iter\n",
    "    verbose=0\n",
    ")\n",
    "embeddings_tsne = tsne.fit_transform(embeddings_cnn)\n",
    "time_tsne = time.time() - start\n",
    "\n",
    "print(f\"   ‚úÖ t-SNE termin√© en {time_tsne:.2f}s\")\n",
    "results['t-SNE'] = {'data': embeddings_tsne, 'time': time_tsne}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. UMAP\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nüîÑ [2/3] UMAP en cours...\")\n",
    "start = time.time()\n",
    "\n",
    "reducer_umap = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "embeddings_umap = reducer_umap.fit_transform(embeddings_cnn)\n",
    "time_umap = time.time() - start\n",
    "\n",
    "print(f\"   ‚úÖ UMAP termin√© en {time_umap:.2f}s\")\n",
    "results['UMAP'] = {'data': embeddings_umap, 'time': time_umap}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. PaCMAP\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nüîÑ [3/3] PaCMAP en cours...\")\n",
    "start = time.time()\n",
    "\n",
    "reducer_pacmap = pacmap.PaCMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    MN_ratio=0.5,\n",
    "    FP_ratio=2.0,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "embeddings_pacmap = reducer_pacmap.fit_transform(embeddings_cnn, init=\"pca\")\n",
    "time_pacmap = time.time() - start\n",
    "\n",
    "print(f\"   ‚úÖ PaCMAP termin√© en {time_pacmap:.2f}s\")\n",
    "results['PaCMAP'] = {'data': embeddings_pacmap, 'time': time_pacmap}\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISATION COMPARATIVE 1√ó3\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüìä G√©n√©ration des visualisations...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "fig.suptitle('Embeddings CNN - Comparaison des M√©thodes de R√©duction\\n'\n",
    "             'Chaque point = 1 image du test set, couleur = chiffre r√©el', \n",
    "             fontsize=18, y=0.98, fontweight='bold')\n",
    "\n",
    "methods_plot = [\n",
    "    ('t-SNE', embeddings_tsne, axes[0], 'Pr√©serve les voisinages locaux'),\n",
    "    ('UMAP', embeddings_umap, axes[1], 'Pr√©serve la topologie globale'),\n",
    "    ('PaCMAP', embeddings_pacmap, axes[2], '√âquilibre local/global')\n",
    "]\n",
    "\n",
    "for method_name, data, ax, subtitle in methods_plot:\n",
    "    # Scatter plot\n",
    "    scatter = ax.scatter(\n",
    "        data[:, 0], data[:, 1], \n",
    "        c=y_true, cmap='tab10',\n",
    "        alpha=0.6, s=30, \n",
    "        edgecolors='black', linewidth=0.2\n",
    "    )\n",
    "    \n",
    "    # Titres et labels\n",
    "    ax.set_title(f'{method_name}\\n{subtitle}', \n",
    "                 fontsize=14, pad=10, fontweight='bold')\n",
    "    ax.set_xlabel(f'{method_name} Dimension 1', fontsize=12)\n",
    "    ax.set_ylabel(f'{method_name} Dimension 2', fontsize=12)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Temps d'ex√©cution\n",
    "    time_text = f\"‚è±Ô∏è {results[method_name]['time']:.2f}s\"\n",
    "    ax.text(0.02, 0.98, time_text, transform=ax.transAxes,\n",
    "           fontsize=11, verticalalignment='top', weight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, \n",
    "                    edgecolor='black', linewidth=1.5))\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, ticks=range(10))\n",
    "    cbar.set_label('Chiffre', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_embeddings_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISATION PAR CLASSE (GRILLE 3√ó10)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüìä G√©n√©ration des vues par classe (grille 3√ó10)...\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 10, figsize=(28, 10))\n",
    "fig.suptitle('Vue par Classe - Embeddings CNN\\n'\n",
    "             'Chaque sous-graphe montre o√π se situent les exemples d\\'un chiffre sp√©cifique', \n",
    "             fontsize=16, y=0.995, fontweight='bold')\n",
    "\n",
    "methods_data = [\n",
    "    ('t-SNE', embeddings_tsne),\n",
    "    ('UMAP', embeddings_umap),\n",
    "    ('PaCMAP', embeddings_pacmap)\n",
    "]\n",
    "\n",
    "for row, (method_name, data) in enumerate(methods_data):\n",
    "    for digit in range(10):\n",
    "        ax = axes[row, digit]\n",
    "        \n",
    "        # Masque pour le chiffre actuel\n",
    "        mask_digit = (y_true == digit)\n",
    "        \n",
    "        # Afficher tous les points en gris (background)\n",
    "        ax.scatter(data[~mask_digit, 0], data[~mask_digit, 1],\n",
    "                   c='lightgray', alpha=0.15, s=5)\n",
    "        \n",
    "        # Afficher le chiffre actuel en couleur\n",
    "        ax.scatter(data[mask_digit, 0], data[mask_digit, 1],\n",
    "                   c=f'C{digit}', alpha=0.8, s=20, \n",
    "                   edgecolors='black', linewidth=0.2)\n",
    "        \n",
    "        # Labels\n",
    "        if digit == 0:\n",
    "            ax.set_ylabel(method_name, fontsize=12, fontweight='bold', \n",
    "                         rotation=0, labelpad=30, va='center')\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(f'Chiffre {digit}', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_embeddings_per_class.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSE QUANTITATIVE\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üìä ANALYSE QUANTITATIVE DES EMBEDDINGS CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculer les m√©triques de clustering\n",
    "metrics = {}\n",
    "for name, result in results.items():\n",
    "    data = result['data']\n",
    "    \n",
    "    # Silhouette Score : mesure la coh√©sion et s√©paration des clusters\n",
    "    # Valeur entre -1 et 1, plus √©lev√© = mieux\n",
    "    sil = silhouette_score(data, y_true)\n",
    "    \n",
    "    # Davies-Bouldin Index : mesure la compacit√© des clusters\n",
    "    # Plus bas = mieux\n",
    "    db = davies_bouldin_score(data, y_true)\n",
    "    \n",
    "    metrics[name] = {\n",
    "        'silhouette': sil,\n",
    "        'davies_bouldin': db,\n",
    "        'time': result['time']\n",
    "    }\n",
    "\n",
    "# Tableau comparatif\n",
    "print(f\"\\n{'M√©thode':<10} {'Silhouette':<15} {'Davies-B':<15} {'Temps (s)':<12} {'Qualit√©'}\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "for method in ['t-SNE', 'UMAP', 'PaCMAP']:\n",
    "    scores = metrics[method]\n",
    "    sil = scores['silhouette']\n",
    "    db = scores['davies_bouldin']\n",
    "    t = scores['time']\n",
    "    \n",
    "    # √âvaluation de la qualit√©\n",
    "    if sil > 0.7:\n",
    "        quality = \"ü•á Excellente\"\n",
    "    elif sil > 0.5:\n",
    "        quality = \"ü•à Tr√®s bonne\"\n",
    "    elif sil > 0.4:\n",
    "        quality = \"ü•â Bonne\"\n",
    "    else:\n",
    "        quality = \"‚ö†Ô∏è  Mod√©r√©e\"\n",
    "    \n",
    "    print(f\"{method:<10} {sil:>6.4f} {'':8} {db:>6.4f} {'':8} {t:>6.2f} {'':5} {quality}\")\n",
    "\n",
    "# Identifier la meilleure m√©thode\n",
    "best_method = max(metrics.items(), key=lambda x: x[1]['silhouette'])\n",
    "fastest_method = min(metrics.items(), key=lambda x: x[1]['time'])\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 75)\n",
    "print(\"üèÜ CLASSEMENT\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"ü•á Meilleure qualit√© : {best_method[0]} (Silhouette = {best_method[1]['silhouette']:.4f})\")\n",
    "print(f\"‚ö° Plus rapide : {fastest_method[0]} ({fastest_method[1]['time']:.2f}s)\")\n",
    "\n",
    "# ============================================================================\n",
    "# GRAPHIQUE PERFORMANCE vs QUALIT√â\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüìä G√©n√©ration du graphique compromis vitesse/qualit√©...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "methods_list = ['t-SNE', 'UMAP', 'PaCMAP']\n",
    "times = [metrics[m]['time'] for m in methods_list]\n",
    "silhouettes = [metrics[m]['silhouette'] for m in methods_list]\n",
    "colors = ['#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, method in enumerate(methods_list):\n",
    "    # Point\n",
    "    ax.scatter(times[i], silhouettes[i], s=600, c=colors[i], alpha=0.7,\n",
    "              edgecolors='black', linewidth=3, zorder=3)\n",
    "    \n",
    "    # Annotation\n",
    "    ax.annotate(method, (times[i], silhouettes[i]), \n",
    "               fontsize=14, weight='bold', ha='center',\n",
    "               xytext=(0, -60), textcoords='offset points',\n",
    "               bbox=dict(boxstyle='round,pad=0.7', facecolor='white', \n",
    "                        edgecolor=colors[i], linewidth=2, alpha=0.9),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2.5, color=colors[i]))\n",
    "\n",
    "# Labels et titre\n",
    "ax.set_xlabel('Temps d\\'ex√©cution (secondes)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Silhouette Score (qualit√© de clustering)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Compromis Vitesse vs Qualit√© - Embeddings CNN', \n",
    "             fontsize=17, pad=20, fontweight='bold')\n",
    "ax.grid(alpha=0.4, linestyle='--', linewidth=1)\n",
    "ax.set_xlim(left=-5)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Zones de qualit√©\n",
    "ax.axhspan(0.7, 1.0, alpha=0.1, color='green', label='Excellente s√©paration (>0.7)', zorder=0)\n",
    "ax.axhspan(0.5, 0.7, alpha=0.1, color='orange', label='Tr√®s bonne s√©paration (0.5-0.7)', zorder=0)\n",
    "ax.axhspan(0.3, 0.5, alpha=0.1, color='yellow', label='Bonne s√©paration (0.3-0.5)', zorder=0)\n",
    "ax.legend(loc='lower right', fontsize=12, framealpha=0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'cnn_embeddings_speed_quality.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# INTERPR√âTATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üí° INTERPR√âTATION DES R√âSULTATS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä Silhouette Score : {best_method[1]['silhouette']:.4f}\n",
    "   ‚Üí Le CNN a appris des repr√©sentations o√π les chiffres de m√™me classe\n",
    "     sont regroup√©s ensemble, et bien s√©par√©s des autres classes.\n",
    "\n",
    "‚ö° Vitesse : {fastest_method[0]} est {times[0]/times[2]:.1f}√ó plus rapide que t-SNE\n",
    "\n",
    "üéØ Recommandation : \n",
    "   ‚Üí Utiliser {best_method[0]} pour visualiser les embeddings CNN\n",
    "   ‚Üí Cette m√©thode offre le meilleur compromis qualit√©/vitesse\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ VISUALISATION CNN TERMIN√âE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìÅ Tous les graphiques sauvegard√©s dans : {GRAPH_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Handwritten-Digits-Classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
