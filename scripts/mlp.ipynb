{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc00567",
   "metadata": {},
   "source": [
    "# ğŸ“¦ CELLULE 1 : Imports et Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d03de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              MNIST MLP - Classification de Chiffres Manuscrits           â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  Architecture : Multi-Layer Perceptron (Fully Connected)                 â•‘\n",
    "â•‘  Objectif : Classifier les chiffres MNIST (0-9)                          â•‘\n",
    "â•‘  Techniques : Optimisation bayÃ©sienne, Early stopping, RÃ©gularisation    â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Librairies standards\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn - MÃ©triques\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    confusion_matrix,\n",
    "    classification_report, \n",
    "    silhouette_score,\n",
    "    davies_bouldin_score\n",
    ")\n",
    "\n",
    "# RÃ©duction de dimensionnalitÃ©\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Optimisation bayÃ©sienne\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances, plot_optimization_history\n",
    "\n",
    "# RÃ©duction de dimensionnalitÃ© avancÃ©e\n",
    "try:\n",
    "    import umap\n",
    "    print(\"âœ… UMAP disponible\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  UMAP non installÃ© - Installer avec: pip install umap-learn\")\n",
    "\n",
    "try:\n",
    "    import pacmap\n",
    "    print(\"âœ… PaCMAP disponible\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  PaCMAP non installÃ© - Installer avec: pip install pacmap\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION GLOBALE\n",
    "# ============================================================================\n",
    "\n",
    "# Seed pour reproductibilitÃ©\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Device (GPU si disponible, sinon CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âš™ï¸  CONFIGURATION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"ğŸ–¥ï¸  Device : {device}\")\n",
    "print(f\"ğŸ² Random seed : {RANDOM_SEED}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"ğŸš€ GPU : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ MÃ©moire GPU : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHEMINS DES FICHIERS\n",
    "# ============================================================================\n",
    "\n",
    "# Configuration pour Google Drive (adapter selon ton environnement)\n",
    "DRIVE_PATH = '/content/drive/MyDrive/La Plateforme/Handwritten Digits'\n",
    "\n",
    "# Chemins des donnÃ©es\n",
    "DATA_TRAIN_PATH = f'{DRIVE_PATH}/mnist_train.csv'\n",
    "DATA_TEST_PATH = f'{DRIVE_PATH}/mnist_test.csv'\n",
    "\n",
    "# Chemins de sauvegarde\n",
    "MODEL_PATH = f'{DRIVE_PATH}/model_final_MLP.pth'\n",
    "HYPERPARAMS_PATH = f'{DRIVE_PATH}/best_hyperparams_MLP.json'\n",
    "GRAPH_DIR = Path(f'{DRIVE_PATH}/graphiques')\n",
    "\n",
    "# CrÃ©er le dossier de graphiques si nÃ©cessaire\n",
    "GRAPH_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"\\nğŸ“‚ Chemins configurÃ©s :\")\n",
    "print(f\"   Train : {DATA_TRAIN_PATH}\")\n",
    "print(f\"   Test  : {DATA_TEST_PATH}\")\n",
    "print(f\"   ModÃ¨le : {MODEL_PATH}\")\n",
    "print(f\"   HyperparamÃ¨tres : {HYPERPARAMS_PATH}\")\n",
    "print(f\"   Graphiques : {GRAPH_DIR}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… CONFIGURATION TERMINÃ‰E\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a4807",
   "metadata": {},
   "source": [
    "# ğŸ“Š CELLULE 2 : Chargement et PrÃ©paration des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                  CHARGEMENT ET SPLIT DES DONNÃ‰ES                         â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "def load_mnist_data(train_path, test_path, train_split=0.8, shuffle=True):\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es MNIST et effectue un split train/dev/test.\n",
    "    \n",
    "    Le dataset original MNIST train (60,000) est divisÃ© en :\n",
    "    - Train set : 80% (pour l'entraÃ®nement)\n",
    "    - Dev set : 20% (pour la validation et l'early stopping)\n",
    "    Le test set (10,000) reste sÃ©parÃ© pour l'Ã©valuation finale.\n",
    "    \n",
    "    Args:\n",
    "        train_path (str): Chemin vers mnist_train.csv\n",
    "        test_path (str): Chemin vers mnist_test.csv\n",
    "        train_split (float): Proportion pour le train set (0.8 = 80%)\n",
    "        shuffle (bool): MÃ©langer les donnÃ©es avant le split\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X_train, Y_train, X_dev, Y_dev, X_test, Y_test)\n",
    "               Tous les tensors sont sur le device configurÃ© (GPU/CPU)\n",
    "               Shape: X = (features, batch), Y = (batch,)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“¥ CHARGEMENT DES DONNÃ‰ES MNIST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CHARGEMENT DU TRAIN SET\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nğŸ”„ Chargement du train set...\")\n",
    "    data_train_full = pd.read_csv(train_path)\n",
    "    data_train_full = np.array(data_train_full)\n",
    "    \n",
    "    print(f\"   âœ… {len(data_train_full):,} exemples chargÃ©s\")\n",
    "    \n",
    "    # MÃ©langer pour randomiser\n",
    "    if shuffle:\n",
    "        np.random.shuffle(data_train_full)\n",
    "        print(f\"   ğŸ”€ DonnÃ©es mÃ©langÃ©es\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CHARGEMENT DU TEST SET\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nğŸ”„ Chargement du test set...\")\n",
    "    data_test_full = pd.read_csv(test_path)\n",
    "    data_test_full = np.array(data_test_full)\n",
    "    \n",
    "    print(f\"   âœ… {len(data_test_full):,} exemples chargÃ©s\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SPLIT TRAIN / DEV\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ”ª Split train/dev ({train_split*100:.0f}/{(1-train_split)*100:.0f})...\")\n",
    "    \n",
    "    split_idx = int(train_split * len(data_train_full))\n",
    "    data_train = data_train_full[:split_idx]\n",
    "    data_dev = data_train_full[split_idx:]\n",
    "    \n",
    "    print(f\"   âœ… Train : {len(data_train):,} exemples\")\n",
    "    print(f\"   âœ… Dev   : {len(data_dev):,} exemples\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CONVERSION EN TENSORS PYTORCH\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nâš™ï¸  Conversion en tensors PyTorch...\")\n",
    "    \n",
    "    # Train\n",
    "    Y_train = torch.tensor(data_train[:, -1], dtype=torch.long).to(device)\n",
    "    X_train = torch.tensor(data_train[:, :-1].T, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Dev\n",
    "    Y_dev = torch.tensor(data_dev[:, -1], dtype=torch.long).to(device)\n",
    "    X_dev = torch.tensor(data_dev[:, :-1].T, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Test\n",
    "    Y_test = torch.tensor(data_test_full[:, -1], dtype=torch.long).to(device)\n",
    "    X_test = torch.tensor(data_test_full[:, :-1].T, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RÃ‰SUMÃ‰\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… DONNÃ‰ES PRÃŠTES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n{'Dataset':<10} {'Samples':<12} {'Shape (X)':<20} {'Shape (Y)':<15} {'Device'}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Train':<10} {X_train.shape[1]:<12,} {str(X_train.shape):<20} {str(Y_train.shape):<15} {X_train.device}\")\n",
    "    print(f\"{'Dev':<10} {X_dev.shape[1]:<12,} {str(X_dev.shape):<20} {str(Y_dev.shape):<15} {X_dev.device}\")\n",
    "    print(f\"{'Test':<10} {X_test.shape[1]:<12,} {str(X_test.shape):<20} {str(Y_test.shape):<15} {X_test.device}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Format : X = (features, batch) | Y = (batch,)\")\n",
    "    print(f\"ğŸ“Š Dtype : X = {X_train.dtype} | Y = {Y_train.dtype}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev, X_test, Y_test\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LES DONNÃ‰ES\n",
    "# ============================================================================\n",
    "\n",
    "X_train, Y_train, X_dev, Y_dev, X_test, Y_test = load_mnist_data(\n",
    "    DATA_TRAIN_PATH, \n",
    "    DATA_TEST_PATH,\n",
    "    train_split=0.8,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f41c9",
   "metadata": {},
   "source": [
    "# ğŸ§  CELLULE 3 : DÃ©finition de l'Architecture MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                   ARCHITECTURE MLP (MULTI-LAYER PERCEPTRON)              â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron pour classification MNIST.\n",
    "    \n",
    "    Architecture configurable avec :\n",
    "    - Nombre de couches cachÃ©es variable\n",
    "    - Taille de chaque couche configurable\n",
    "    - Choix de la fonction d'activation\n",
    "    - Dropout pour rÃ©gularisation\n",
    "    - Batch Normalization optionnelle\n",
    "    - Initialisation des poids (He ou Xavier)\n",
    "    \n",
    "    Args:\n",
    "        layer_sizes (list): Liste des tailles de couches cachÃ©es\n",
    "                           Ex: [256, 128, 64] = 3 couches cachÃ©es\n",
    "        activation (str): Fonction d'activation ('relu', 'leaky_relu', 'tanh', 'gelu')\n",
    "        init_method (str): MÃ©thode d'initialisation ('he', 'xavier')\n",
    "        dropout (float): Taux de dropout (0.0 = pas de dropout)\n",
    "        batch_norm (bool): Utiliser la batch normalization\n",
    "    \n",
    "    Example:\n",
    "        >>> model = MLP(layer_sizes=[256, 128], activation='relu', dropout=0.3)\n",
    "        >>> output = model(X_train)  # Shape: (batch_size, 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes, activation='relu', init_method='he',\n",
    "                 dropout=0.0, batch_norm=False):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CONFIGURATION\n",
    "        # ====================================================================\n",
    "        \n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.use_batch_norm = batch_norm\n",
    "        \n",
    "        # Stockage des couches\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList() if batch_norm else None\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CONSTRUCTION DES COUCHES CACHÃ‰ES\n",
    "        # ====================================================================\n",
    "        \n",
    "        input_size = 784  # MNIST = 28Ã—28 pixels\n",
    "        \n",
    "        for hidden_size in layer_sizes:\n",
    "            # Couche linÃ©aire (fully connected)\n",
    "            self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "            \n",
    "            # Batch normalization (optionnelle)\n",
    "            if batch_norm:\n",
    "                self.batch_norms.append(nn.BatchNorm1d(hidden_size))\n",
    "            \n",
    "            input_size = hidden_size  # Pour la prochaine couche\n",
    "        \n",
    "        # ====================================================================\n",
    "        # COUCHE DE SORTIE\n",
    "        # ====================================================================\n",
    "        \n",
    "        self.output_layer = nn.Linear(input_size, 10)  # 10 classes (0-9)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # RÃ‰GULARISATION\n",
    "        # ====================================================================\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # FONCTION D'ACTIVATION\n",
    "        # ====================================================================\n",
    "        \n",
    "        activation_dict = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.01),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'gelu': nn.GELU()\n",
    "        }\n",
    "        \n",
    "        if activation not in activation_dict:\n",
    "            raise ValueError(f\"Activation '{activation}' non supportÃ©e. \"\n",
    "                           f\"Choix: {list(activation_dict.keys())}\")\n",
    "        \n",
    "        self.activation = activation_dict[activation]\n",
    "        \n",
    "        # ====================================================================\n",
    "        # INITIALISATION DES POIDS\n",
    "        # ====================================================================\n",
    "        \n",
    "        self._initialize_weights(init_method)\n",
    "    \n",
    "    \n",
    "    def _initialize_weights(self, init_method):\n",
    "        \"\"\"\n",
    "        Initialise les poids des couches selon la mÃ©thode choisie.\n",
    "        \n",
    "        - He (Kaiming) : RecommandÃ© pour ReLU\n",
    "        - Xavier (Glorot) : RecommandÃ© pour Tanh/Sigmoid\n",
    "        \n",
    "        Args:\n",
    "            init_method (str): 'he' ou 'xavier'\n",
    "        \"\"\"\n",
    "        # Couches cachÃ©es\n",
    "        for layer in self.layers:\n",
    "            if init_method == 'he':\n",
    "                nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "            elif init_method == 'xavier':\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "            else:\n",
    "                raise ValueError(f\"MÃ©thode d'initialisation '{init_method}' non supportÃ©e\")\n",
    "            \n",
    "            nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        # Couche de sortie\n",
    "        if init_method == 'he':\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight)\n",
    "        elif init_method == 'xavier':\n",
    "            nn.init.xavier_normal_(self.output_layer.weight)\n",
    "        \n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass du rÃ©seau.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input de shape (features, batch) = (784, N)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Logits de shape (batch, 10)\n",
    "        \n",
    "        Flow:\n",
    "            (784, N) â†’ Transpose â†’ (N, 784)\n",
    "            â†’ Linear â†’ BatchNorm â†’ Activation â†’ Dropout\n",
    "            â†’ ... (rÃ©pÃ©tÃ© pour chaque couche cachÃ©e)\n",
    "            â†’ Linear (output) â†’ (N, 10)\n",
    "        \"\"\"\n",
    "        # Transposer pour avoir (batch, features)\n",
    "        x = x.T  # (features, batch) â†’ (batch, features)\n",
    "        \n",
    "        # Passage dans les couches cachÃ©es\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            \n",
    "            # Batch normalization (si activÃ©e)\n",
    "            if self.use_batch_norm:\n",
    "                x = self.batch_norms[i](x)\n",
    "            \n",
    "            # Activation\n",
    "            x = self.activation(x)\n",
    "            \n",
    "            # Dropout\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Couche de sortie (pas d'activation, logits bruts)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x  # Shape: (batch, 10)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION D'Ã‰VALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(model, X, Y):\n",
    "    \"\"\"\n",
    "    Ã‰value l'accuracy du modÃ¨le sur un dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): ModÃ¨le Ã  Ã©valuer\n",
    "        X (Tensor): Features (features, batch)\n",
    "        Y (Tensor): Labels (batch,)\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy (entre 0 et 1)\n",
    "    \"\"\"\n",
    "    model.eval()  # Mode Ã©valuation (dÃ©sactive dropout)\n",
    "    \n",
    "    with torch.no_grad():  # Pas de calcul de gradient\n",
    "        outputs = model(X)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # Classe avec max probabilitÃ©\n",
    "        accuracy = (predicted == Y).float().mean().item()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST DE L'ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§  TEST DE L'ARCHITECTURE MLP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# CrÃ©er un modÃ¨le test\n",
    "test_model = MLP(\n",
    "    layer_sizes=[256, 128, 64],\n",
    "    activation='relu',\n",
    "    init_method='he',\n",
    "    dropout=0.3,\n",
    "    batch_norm=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nğŸ“Š Architecture :\")\n",
    "print(f\"   Input : 784 (28Ã—28 pixels)\")\n",
    "print(f\"   Couches cachÃ©es : [256, 128, 64]\")\n",
    "print(f\"   Output : 10 (classes 0-9)\")\n",
    "print(f\"   Activation : ReLU\")\n",
    "print(f\"   Dropout : 0.3\")\n",
    "print(f\"   Batch Norm : True\")\n",
    "\n",
    "# Compter les paramÃ¨tres\n",
    "total_params = sum(p.numel() for p in test_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in test_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nğŸ”¢ Nombre de paramÃ¨tres :\")\n",
    "print(f\"   Total : {total_params:,}\")\n",
    "print(f\"   EntraÃ®nables : {trainable_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nâš™ï¸  Test forward pass...\")\n",
    "with torch.no_grad():\n",
    "    test_output = test_model(X_train[:, :5])  # 5 premiers exemples\n",
    "    print(f\"   Input shape : {X_train[:, :5].shape}\")\n",
    "    print(f\"   Output shape : {test_output.shape}\")\n",
    "    print(f\"   âœ… Forward pass rÃ©ussi\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ARCHITECTURE MLP PRÃŠTE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c03537",
   "metadata": {},
   "source": [
    "# ğŸ¯ CELLULE 4 : Fonction d'EntraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                     FONCTION D'ENTRAÃNEMENT MLP                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "def train_model(X, Y, lr, iterations, layer_sizes, activation, init_method,\n",
    "                l2_lambda, dropout, batch_norm, optimizer_name,\n",
    "                scheduler_name=None, grad_clip=None):\n",
    "    \"\"\"\n",
    "    EntraÃ®ne un modÃ¨le MLP avec les hyperparamÃ¨tres fournis.\n",
    "    \n",
    "    Args:\n",
    "        X (Tensor): Features d'entraÃ®nement (features, batch)\n",
    "        Y (Tensor): Labels (batch,)\n",
    "        lr (float): Learning rate\n",
    "        iterations (int): Nombre d'epochs\n",
    "        layer_sizes (list): Architecture du rÃ©seau\n",
    "        activation (str): Fonction d'activation\n",
    "        init_method (str): MÃ©thode d'initialisation\n",
    "        l2_lambda (float): Coefficient de rÃ©gularisation L2 (weight decay)\n",
    "        dropout (float): Taux de dropout\n",
    "        batch_norm (bool): Utiliser batch normalization\n",
    "        optimizer_name (str): 'adam', 'adamw', ou 'sgd'\n",
    "        scheduler_name (str): 'plateau' ou None\n",
    "        grad_clip (float): Valeur max pour gradient clipping (None = pas de clipping)\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: ModÃ¨le entraÃ®nÃ©\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CRÃ‰ATION DU MODÃˆLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    model = MLP(\n",
    "        layer_sizes=layer_sizes,\n",
    "        activation=activation,\n",
    "        init_method=init_method,\n",
    "        dropout=dropout,\n",
    "        batch_norm=batch_norm\n",
    "    ).to(device)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOSS ET OPTIMISEUR\n",
    "    # ========================================================================\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Choix de l'optimiseur\n",
    "    optimizer_dict = {\n",
    "        'adam': optuna.Adam(model.parameters(), lr=lr, weight_decay=l2_lambda),\n",
    "        'adamw': optim.AdamW(model.parameters(), lr=lr, weight_decay=l2_lambda),\n",
    "        'sgd': optim.SGD(model.parameters(), lr=lr, weight_decay=l2_lambda, momentum=0.9)\n",
    "    }\n",
    "    \n",
    "    if optimizer_name not in optimizer_dict:\n",
    "        raise ValueError(f\"Optimiseur '{optimizer_name}' non supportÃ©. \"\n",
    "                        f\"Choix: {list(optimizer_dict.keys())}\")\n",
    "    \n",
    "    optimizer = optimizer_dict[optimizer_name]\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LEARNING RATE SCHEDULER (OPTIONNEL)\n",
    "    # ========================================================================\n",
    "    \n",
    "    scheduler = None\n",
    "    if scheduler_name == 'plateau':\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min',      # Minimiser la loss\n",
    "            patience=10,     # Attendre 10 epochs avant de rÃ©duire lr\n",
    "            factor=0.5,      # RÃ©duire lr de moitiÃ©\n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BOUCLE D'ENTRAÃNEMENT\n",
    "    # ========================================================================\n",
    "    \n",
    "    model.train()  # Mode entraÃ®nement\n",
    "    \n",
    "    for epoch in range(iterations):\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (Ã©vite l'explosion des gradients)\n",
    "        if grad_clip:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        # Mise Ã  jour des poids\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Mise Ã  jour du learning rate\n",
    "        if scheduler and scheduler_name == 'plateau':\n",
    "            scheduler.step(loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"âœ… Fonction d'entraÃ®nement dÃ©finie\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612f8dc",
   "metadata": {},
   "source": [
    "# ğŸ”¬ CELLULE 5 : Optimisation BayÃ©sienne avec Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              OPTIMISATION BAYÃ‰SIENNE DES HYPERPARAMÃˆTRES                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Objectif : Trouver automatiquement la meilleure configuration du MLP\n",
    "\n",
    "HyperparamÃ¨tres optimisÃ©s :\n",
    "- Architecture : nombre et taille des couches\n",
    "- Learning rate\n",
    "- RÃ©gularisation L2\n",
    "- Dropout\n",
    "\n",
    "HyperparamÃ¨tres fixÃ©s (dÃ©jÃ  optimaux) :\n",
    "- Activation : ReLU\n",
    "- Initialisation : He\n",
    "- Batch Norm : True\n",
    "- Optimiseur : AdamW\n",
    "- Scheduler : ReduceLROnPlateau\n",
    "- Gradient clipping : 0.5\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”¬ OPTIMISATION BAYÃ‰SIENNE AVEC OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION OBJECTIF\n",
    "# ============================================================================\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    \"\"\"\n",
    "    Fonction objectif pour Optuna : teste une configuration et retourne l'accuracy.\n",
    "    \n",
    "    Args:\n",
    "        trial (optuna.Trial): Object trial contenant les suggestions d'hyperparamÃ¨tres\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy sur le dev set (Ã  maximiser)\n",
    "    \"\"\"\n",
    "    \n",
    "    # SuggÃ©rer les hyperparamÃ¨tres\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 3)  # 2 ou 3 couches cachÃ©es\n",
    "    \n",
    "    layer_sizes = [\n",
    "        trial.suggest_int(f'n_neurons_l{i}', 64, 192, step=32)\n",
    "        for i in range(n_layers)\n",
    "    ]\n",
    "    \n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.01, log=True)\n",
    "    l2_lambda = trial.suggest_float('l2_lambda', 0.005, 0.012, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.5, 0.65)\n",
    "    \n",
    "    # EntraÃ®ner le modÃ¨le\n",
    "    model = train_model(\n",
    "        X=X_train,\n",
    "        Y=Y_train,\n",
    "        lr=lr,\n",
    "        iterations=250,  # Moins d'epochs pour aller plus vite\n",
    "        layer_sizes=layer_sizes,\n",
    "        activation='relu',\n",
    "        init_method='he',\n",
    "        l2_lambda=l2_lambda,\n",
    "        dropout=dropout,\n",
    "        batch_norm=True,\n",
    "        optimizer_name='adamw',\n",
    "        scheduler_name='plateau',\n",
    "        grad_clip=0.5\n",
    "    )\n",
    "    \n",
    "    # Ã‰valuer sur le dev set\n",
    "    dev_accuracy = evaluate_model(model, X_dev, Y_dev)\n",
    "    \n",
    "    return dev_accuracy\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LANCER L'OPTIMISATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸš€ Lancement de l'optimisation...\")\n",
    "print(f\"   â€¢ Nombre de trials : 50\")\n",
    "print(f\"   â€¢ Sampler : TPE (Tree-structured Parzen Estimator)\")\n",
    "print(f\"   â€¢ Objectif : Maximiser l'accuracy sur dev set\")\n",
    "print(f\"\\nâ±ï¸  Temps estimÃ© : 10-15 minutes\\n\")\n",
    "\n",
    "# CrÃ©er l'Ã©tude Optuna\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # Maximiser l'accuracy\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    ")\n",
    "\n",
    "# Optimiser\n",
    "study.optimize(\n",
    "    optuna_objective, \n",
    "    n_trials=50,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# RÃ‰SULTATS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ† RÃ‰SULTATS DE L'OPTIMISATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ… Meilleure accuracy dev : {study.best_value:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Meilleurs hyperparamÃ¨tres :\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"   â€¢ {key:<20} : {value}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDER LES HYPERPARAMÃˆTRES\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nğŸ’¾ Sauvegarde des hyperparamÃ¨tres...\")\n",
    "\n",
    "best_params = {\n",
    "    'n_layers': study.best_params['n_layers'],\n",
    "    'layer_sizes': [\n",
    "        study.best_params[f'n_neurons_l{i}']\n",
    "        for i in range(study.best_params['n_layers'])\n",
    "    ],\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': study.best_params['learning_rate'],\n",
    "    'iterations': 300,  # Plus d'epochs pour l'entraÃ®nement final\n",
    "    'l2_lambda': study.best_params['l2_lambda'],\n",
    "    'dropout': study.best_params['dropout'],\n",
    "    'batch_norm': True,\n",
    "    'init_method': 'he',\n",
    "    'optimizer': 'adamw',\n",
    "    'scheduler': 'plateau',\n",
    "    'grad_clip': 0.5,\n",
    "    'best_dev_accuracy': study.best_value\n",
    "}\n",
    "\n",
    "with open(HYPERPARAMS_PATH, 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "print(f\"   âœ… SauvegardÃ© dans : {HYPERPARAMS_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… OPTIMISATION TERMINÃ‰E\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2af30",
   "metadata": {},
   "source": [
    "# ğŸ“ˆ CELLULE 6 : Graphiques Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62507315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              VISUALISATION DES RÃ‰SULTATS OPTUNA                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Š GÃ©nÃ©ration des graphiques Optuna...\")\n",
    "\n",
    "# ============================================================================\n",
    "# GRAPHIQUE 1 : HISTORIQUE D'OPTIMISATION\n",
    "# ============================================================================\n",
    "\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.update_layout(\n",
    "    title=\"Historique d'Optimisation BayÃ©sienne\",\n",
    "    xaxis_title=\"Trial\",\n",
    "    yaxis_title=\"Dev Accuracy\",\n",
    "    width=1200,\n",
    "    height=600\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# ============================================================================\n",
    "# GRAPHIQUE 2 : IMPORTANCE DES HYPERPARAMÃˆTRES\n",
    "# ============================================================================\n",
    "\n",
    "fig2 = plot_param_importances(study)\n",
    "fig2.update_layout(\n",
    "    title=\"Importance des HyperparamÃ¨tres\",\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "fig2.show()\n",
    "\n",
    "print(\"âœ… Graphiques Optuna affichÃ©s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91456e",
   "metadata": {},
   "source": [
    "# ğŸ¯ CELLULE 7 : EntraÃ®nement Final avec Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              ENTRAÃNEMENT FINAL AVEC EARLY STOPPING                      â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Utilise les meilleurs hyperparamÃ¨tres trouvÃ©s par Optuna\n",
    "ImplÃ©mente l'early stopping pour Ã©viter le surapprentissage\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ ENTRAÃNEMENT FINAL DU MODÃˆLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LES MEILLEURS HYPERPARAMÃˆTRES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸ”„ Chargement des hyperparamÃ¨tres optimisÃ©s...\")\n",
    "\n",
    "with open(HYPERPARAMS_PATH, 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(f\"âœ… HyperparamÃ¨tres chargÃ©s :\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION D'ENTRAÃNEMENT AVEC EARLY STOPPING\n",
    "# ============================================================================\n",
    "\n",
    "def train_with_early_stopping(X_train, Y_train, X_val, Y_val, hyperparams, \n",
    "                               patience=3):\n",
    "    \"\"\"\n",
    "    EntraÃ®ne le modÃ¨le avec early stopping et learning rate scheduling.\n",
    "    \n",
    "    Early Stopping : ArrÃªte l'entraÃ®nement si la validation accuracy \n",
    "                     ne s'amÃ©liore pas pendant 'patience' evaluations.\n",
    "    \n",
    "    Args:\n",
    "        X_train, Y_train: DonnÃ©es d'entraÃ®nement\n",
    "        X_val, Y_val: DonnÃ©es de validation\n",
    "        hyperparams (dict): Dictionnaire des hyperparamÃ¨tres\n",
    "        patience (int): Nombre d'epochs sans amÃ©lioration avant arrÃªt\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, best_val_acc, history)\n",
    "               - model: Meilleur modÃ¨le (state du meilleur epoch)\n",
    "               - best_val_acc: Meilleure accuracy validation\n",
    "               - history: Historique d'entraÃ®nement\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # INITIALISATION DU MODÃˆLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nğŸ—ï¸  Construction du modÃ¨le...\")\n",
    "    \n",
    "    model = MLP(\n",
    "        layer_sizes=hyperparams['layer_sizes'],\n",
    "        activation=hyperparams['activation'],\n",
    "        init_method=hyperparams['init_method'],\n",
    "        dropout=hyperparams['dropout'],\n",
    "        batch_norm=hyperparams['batch_norm']\n",
    "    ).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   âœ… Architecture : {hyperparams['layer_sizes']}\")\n",
    "    print(f\"   âœ… ParamÃ¨tres : {total_params:,}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # OPTIMISEUR ET SCHEDULER\n",
    "    # ========================================================================\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=hyperparams['learning_rate'],\n",
    "        weight_decay=hyperparams['l2_lambda']\n",
    "    )\n",
    "    \n",
    "    # RÃ©duire le learning rate si la validation accuracy stagne\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',      # Maximiser l'accuracy\n",
    "        patience=5,      # Attendre 5 evaluations\n",
    "        factor=0.5,      # Diviser lr par 2\n",
    "        verbose=True     # Afficher les changements de lr\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # INITIALISATION DE L'HISTORIQUE\n",
    "    # ========================================================================\n",
    "    \n",
    "    history = {\n",
    "        'epochs': [],\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_accs': [],\n",
    "        'val_accs': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BOUCLE D'ENTRAÃNEMENT\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nğŸš€ DÃ©but de l'entraÃ®nement...\")\n",
    "    print(f\"   â€¢ Epochs max : {hyperparams.get('iterations', 300)}\")\n",
    "    print(f\"   â€¢ Early stopping patience : {patience}\")\n",
    "    print(f\"   â€¢ Evaluation tous les 5 epochs\\n\")\n",
    "    \n",
    "    for epoch in range(hyperparams.get('iterations', 300)):\n",
    "        # ====================================================================\n",
    "        # PHASE D'ENTRAÃNEMENT\n",
    "        # ====================================================================\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, Y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        if hyperparams.get('grad_clip'):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), \n",
    "                hyperparams['grad_clip']\n",
    "            )\n",
    "        \n",
    "        # Mise Ã  jour des poids\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Ã‰VALUATION (tous les 5 epochs)\n",
    "        # ====================================================================\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # MÃ©triques train\n",
    "                train_loss = loss.item()\n",
    "                train_acc = evaluate_model(model, X_train, Y_train)\n",
    "                \n",
    "                # MÃ©triques validation\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss = criterion(val_outputs, Y_val).item()\n",
    "                val_acc = evaluate_model(model, X_val, Y_val)\n",
    "            \n",
    "            # Mise Ã  jour du scheduler\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # Sauvegarder l'historique\n",
    "            history['epochs'].append(epoch)\n",
    "            history['train_losses'].append(train_loss)\n",
    "            history['val_losses'].append(val_loss)\n",
    "            history['train_accs'].append(train_acc)\n",
    "            history['val_accs'].append(val_acc)\n",
    "            \n",
    "            # Affichage\n",
    "            if epoch % 50 == 0:\n",
    "                print(f\"ğŸ“Š Epoch {epoch:3d} â†’ \"\n",
    "                      f\"Train: {train_acc:.2%} (loss: {train_loss:.4f}) | \"\n",
    "                      f\"Val: {val_acc:.2%} (loss: {val_loss:.4f})\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # EARLY STOPPING LOGIC\n",
    "            # ================================================================\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                # Nouvelle meilleure accuracy â†’ sauvegarder le modÃ¨le\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "                \n",
    "                # Indicateur visuel\n",
    "                if epoch % 50 == 0:\n",
    "                    print(f\"   âœ¨ Nouveau meilleur modÃ¨le ! Val Acc: {best_val_acc:.4f}\")\n",
    "            \n",
    "            else:\n",
    "                # Pas d'amÃ©lioration â†’ incrÃ©menter le compteur\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # ArrÃªt si patience dÃ©passÃ©e\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nğŸ›‘ Early stopping dÃ©clenchÃ© Ã  l'epoch {epoch}\")\n",
    "                print(f\"   â€¢ Meilleure val accuracy : {best_val_acc:.4f}\")\n",
    "                print(f\"   â€¢ Atteinte Ã  l'epoch : {epoch - patience*5}\")\n",
    "                break\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RESTAURER LE MEILLEUR MODÃˆLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\nâœ… Meilleur modÃ¨le restaurÃ©\")\n",
    "    \n",
    "    return model, best_val_acc, history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENTRAÃNER LE MODÃˆLE FINAL\n",
    "# ============================================================================\n",
    "\n",
    "model_final, final_val_acc, history = train_with_early_stopping(\n",
    "    X_train, Y_train, \n",
    "    X_dev, Y_dev, \n",
    "    best_params, \n",
    "    patience=3\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDER LE MODÃˆLE\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nğŸ’¾ Sauvegarde du modÃ¨le...\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_final.state_dict(),\n",
    "    'hyperparams': best_params,\n",
    "    'val_accuracy': final_val_acc,\n",
    "    'train_history': history\n",
    "}, MODEL_PATH)\n",
    "\n",
    "print(f\"   âœ… ModÃ¨le sauvegardÃ© : {MODEL_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"âœ… ENTRAÃNEMENT TERMINÃ‰ - Val Accuracy: {final_val_acc:.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2520b76",
   "metadata": {},
   "source": [
    "# ğŸ“ˆ CELLULE 8 : Graphique - Courbes d'Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘            GRAPHIQUE : COURBES D'APPRENTISSAGE (TRAINING HISTORY)        â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Š GÃ©nÃ©ration du graphique : Courbes d'apprentissage\")\n",
    "\n",
    "# ============================================================================\n",
    "# GRAPHIQUE AVEC DOUBLE AXE Y\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# ========================================================================\n",
    "# AXE 1 : ACCURACY\n",
    "# ========================================================================\n",
    "\n",
    "ax1.plot(history['epochs'], history['train_accs'], \n",
    "         label='Train Accuracy', linewidth=2.5, color='#4ECDC4', marker='o', markersize=4)\n",
    "ax1.plot(history['epochs'], history['val_accs'], \n",
    "         label='Val Accuracy', linewidth=2.5, linestyle='--', color='#45B7D1', marker='s', markersize=4)\n",
    "\n",
    "ax1.set_xlabel('Epochs', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=13, fontweight='bold', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=11)\n",
    "ax1.tick_params(axis='x', labelsize=11)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.7)\n",
    "ax1.legend(loc='lower right', fontsize=12, framealpha=0.95)\n",
    "\n",
    "# ========================================================================\n",
    "# AXE 2 : LOSS\n",
    "# ========================================================================\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.plot(history['epochs'], history['train_losses'], \n",
    "         label='Train Loss', linewidth=2.5, linestyle='-', color='#FF6B6B', marker='^', markersize=4)\n",
    "ax2.plot(history['epochs'], history['val_losses'], \n",
    "         label='Val Loss', linewidth=2.5, linestyle='--', color='#EE5A6F', marker='v', markersize=4)\n",
    "\n",
    "ax2.set_ylabel('Loss', fontsize=13, fontweight='bold', color='tab:red')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=11)\n",
    "ax2.set_ylim([0, max(history['train_losses'] + history['val_losses']) * 1.1])\n",
    "ax2.legend(loc='upper right', fontsize=12, framealpha=0.95)\n",
    "\n",
    "# ========================================================================\n",
    "# TITRE ET ANNOTATIONS\n",
    "# ========================================================================\n",
    "\n",
    "plt.title('Courbes d\\'Apprentissage - MLP MNIST\\n'\n",
    "          f'Meilleure Val Accuracy: {final_val_acc:.4f}',\n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Annoter le meilleur point\n",
    "best_epoch_idx = history['val_accs'].index(max(history['val_accs']))\n",
    "best_epoch = history['epochs'][best_epoch_idx]\n",
    "best_acc = history['val_accs'][best_epoch_idx]\n",
    "\n",
    "ax1.annotate(f'Best: {best_acc:.4f}',\n",
    "             xy=(best_epoch, best_acc),\n",
    "             xytext=(best_epoch + 20, best_acc - 0.05),\n",
    "             fontsize=11, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', lw=2, color='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'mlp_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Graphique sauvegardÃ© : {GRAPH_DIR / 'mlp_training_history.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d94a87",
   "metadata": {},
   "source": [
    "# ğŸ§ª CELLULE 9 : Ã‰valuation sur le Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                  Ã‰VALUATION FINALE SUR LE TEST SET                       â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§ª Ã‰VALUATION SUR LE TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LE MODÃˆLE FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸ”„ Chargement du modÃ¨le final...\")\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "best_params = checkpoint['hyperparams']\n",
    "\n",
    "model_final = MLP(\n",
    "    layer_sizes=best_params['layer_sizes'],\n",
    "    activation=best_params['activation'],\n",
    "    init_method=best_params['init_method'],\n",
    "    dropout=best_params['dropout'],\n",
    "    batch_norm=best_params['batch_norm']\n",
    ").to(device)\n",
    "\n",
    "model_final.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"âœ… ModÃ¨le chargÃ©\")\n",
    "print(f\"   â€¢ Architecture : {best_params['layer_sizes']}\")\n",
    "print(f\"   â€¢ Val Accuracy : {checkpoint['val_accuracy']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRÃ‰DICTIONS SUR LE TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸ”„ GÃ©nÃ©ration des prÃ©dictions...\")\n",
    "\n",
    "model_final.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    test_outputs = model_final(X_test)\n",
    "    \n",
    "    # ProbabilitÃ©s (softmax)\n",
    "    test_probs = torch.softmax(test_outputs, dim=1)\n",
    "    \n",
    "    # PrÃ©dictions (classe avec max probabilitÃ©)\n",
    "    _, test_pred = torch.max(test_outputs, 1)\n",
    "    \n",
    "    # Convertir en numpy pour sklearn\n",
    "    y_true = Y_test.cpu().numpy()\n",
    "    y_pred = test_pred.cpu().numpy()\n",
    "    y_probs = test_probs.cpu().numpy()\n",
    "\n",
    "print(f\"âœ… PrÃ©dictions gÃ©nÃ©rÃ©es pour {len(y_true):,} exemples\")\n",
    "\n",
    "# ============================================================================\n",
    "# MÃ‰TRIQUES GLOBALES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸ“Š Calcul des mÃ©triques...\")\n",
    "\n",
    "# Accuracy\n",
    "test_acc = (test_pred == Y_test).float().mean().item()\n",
    "\n",
    "# AUC-ROC (One-vs-Rest pour multiclasse)\n",
    "auc_score = roc_auc_score(y_true, y_probs, multi_class='ovr', average='macro')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ RÃ‰SULTATS FINAUX\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nâœ… Test Accuracy : {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"âœ… AUC-ROC (macro): {auc_score:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RAPPORT DE CLASSIFICATION DÃ‰TAILLÃ‰\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š CLASSIFICATION REPORT (par classe)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4, \n",
    "                           target_names=[f'Chiffre {i}' for i in range(10)]))\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTIQUES D'ERREURS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âŒ ANALYSE DES ERREURS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Nombre total d'erreurs\n",
    "n_errors = (y_true != y_pred).sum()\n",
    "error_rate = n_errors / len(y_true)\n",
    "\n",
    "print(f\"\\nğŸ“Š Statistiques globales :\")\n",
    "print(f\"   â€¢ Total exemples : {len(y_true):,}\")\n",
    "print(f\"   â€¢ PrÃ©dictions correctes : {len(y_true) - n_errors:,} ({(1-error_rate)*100:.2f}%)\")\n",
    "print(f\"   â€¢ Erreurs : {n_errors:,} ({error_rate*100:.2f}%)\")\n",
    "\n",
    "# Top 5 paires de confusion\n",
    "from collections import Counter\n",
    "errors = [(y_true[i], y_pred[i]) for i in range(len(y_true)) if y_true[i] != y_pred[i]]\n",
    "error_pairs = Counter(errors).most_common(5)\n",
    "\n",
    "print(f\"\\nğŸ” Top 5 confusions les plus frÃ©quentes :\")\n",
    "for (true_label, pred_label), count in error_pairs:\n",
    "    pct = (count / n_errors) * 100\n",
    "    print(f\"   {true_label} â†’ {pred_label} : {count:3d} fois ({pct:5.2f}% des erreurs)\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10be2e",
   "metadata": {},
   "source": [
    "# ğŸ¨ CELLULE 10 : Graphique - Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              GRAPHIQUE : MATRICE DE CONFUSION                            â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Š GÃ©nÃ©ration de la matrice de confusion...\")\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULER LA MATRICE DE CONFUSION\n",
    "# ============================================================================\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Matrice en pourcentages (par ligne = par classe rÃ©elle)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALISATION\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Heatmap\n",
    "im = ax.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "# Titre\n",
    "ax.set_title('Matrice de Confusion - Test Set\\n'\n",
    "             f'Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)',\n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Nombre de prÃ©dictions', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Axes\n",
    "tick_marks = np.arange(10)\n",
    "ax.set_xticks(tick_marks)\n",
    "ax.set_yticks(tick_marks)\n",
    "ax.set_xticklabels(range(10), fontsize=11)\n",
    "ax.set_yticklabels(range(10), fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Chiffre PrÃ©dit', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Chiffre RÃ©el', fontsize=13, fontweight='bold')\n",
    "\n",
    "# ============================================================================\n",
    "# ANNOTATIONS\n",
    "# ============================================================================\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        value = cm[i, j]\n",
    "        percent = cm_percent[i, j]\n",
    "        \n",
    "        # Mettre en Ã©vidence les erreurs significatives\n",
    "        if i != j and value >= 10:  # Erreur avec >= 10 cas\n",
    "            bbox_props = dict(\n",
    "                boxstyle='round,pad=0.4', \n",
    "                facecolor='red', \n",
    "                alpha=0.3, \n",
    "                edgecolor='darkred',\n",
    "                linewidth=2\n",
    "            )\n",
    "            text_weight = 'bold'\n",
    "        else:\n",
    "            bbox_props = None\n",
    "            text_weight = 'normal'\n",
    "        \n",
    "        # Couleur du texte selon le fond\n",
    "        text_color = 'white' if value > thresh else 'black'\n",
    "        \n",
    "        # Afficher count + pourcentage\n",
    "        ax.text(j, i, f'{value}\\n({percent:.1f}%)',\n",
    "                ha='center', va='center',\n",
    "                color=text_color, \n",
    "                fontsize=10,\n",
    "                fontweight=text_weight,\n",
    "                bbox=bbox_props)\n",
    "\n",
    "# ============================================================================\n",
    "# LÃ‰GENDE\n",
    "# ============================================================================\n",
    "\n",
    "# Ajouter une note explicative\n",
    "legend_text = (\n",
    "    \"ğŸ“Š InterprÃ©tation :\\n\"\n",
    "    \"â€¢ Diagonale = PrÃ©dictions correctes\\n\"\n",
    "    \"â€¢ Cases rouges = Confusions frÃ©quentes (â‰¥10 cas)\\n\"\n",
    "    \"â€¢ Pourcentages = % par rapport au total de la classe rÃ©elle\"\n",
    ")\n",
    "\n",
    "ax.text(0.02, -0.15, legend_text,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round,pad=0.7', facecolor='lightyellow', \n",
    "                 alpha=0.9, edgecolor='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'mlp_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Graphique sauvegardÃ© : {GRAPH_DIR / 'mlp_confusion_matrix.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37849897",
   "metadata": {},
   "source": [
    "# ğŸ—ºï¸ CELLULE 11 : Extraction des Embeddings MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              EXTRACTION DES EMBEDDINGS (DERNIÃˆRE COUCHE)                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Objectif : Capturer les activations de la derniÃ¨re couche cachÃ©e du MLP\n",
    "Ces embeddings reprÃ©sentent comment le rÃ©seau \"voit\" les images aprÃ¨s apprentissage\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ—ºï¸  EXTRACTION DES EMBEDDINGS MLP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFIER SI EMBEDDINGS DÃ‰JÃ€ EN MÃ‰MOIRE\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    _ = embeddings\n",
    "    print(f\"âœ… Embeddings dÃ©jÃ  en mÃ©moire - Shape: {embeddings.shape}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nğŸ”„ Extraction des embeddings de la derniÃ¨re couche...\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CRÃ‰ER UN HOOK POUR CAPTURER LES ACTIVATIONS\n",
    "    # ========================================================================\n",
    "    \n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        \"\"\"\n",
    "        Factory function pour crÃ©er un hook.\n",
    "        \n",
    "        Le hook capture automatiquement la sortie de la couche\n",
    "        lors du forward pass.\n",
    "        \"\"\"\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ATTACHER LE HOOK Ã€ LA DERNIÃˆRE COUCHE CACHÃ‰E\n",
    "    # ========================================================================\n",
    "    \n",
    "    # model_final.layers[-1] = derniÃ¨re couche cachÃ©e (avant output layer)\n",
    "    target_layer = model_final.layers[-1]\n",
    "    \n",
    "    print(f\"   â€¢ Couche cible : {target_layer}\")\n",
    "    print(f\"   â€¢ Shape attendue : (batch_size, {best_params['layer_sizes'][-1]})\")\n",
    "    \n",
    "    hook_handle = target_layer.register_forward_hook(get_activation('embeddings'))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FORWARD PASS POUR DÃ‰CLENCHER LE HOOK\n",
    "    # ========================================================================\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = model_final(X_test)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RÃ‰CUPÃ‰RER LES EMBEDDINGS\n",
    "    # ========================================================================\n",
    "    \n",
    "    embeddings = activations['embeddings'].cpu().numpy()\n",
    "    y_true = Y_test.cpu().numpy()\n",
    "    \n",
    "    # Retirer le hook\n",
    "    hook_handle.remove()\n",
    "    \n",
    "    print(f\"\\nâœ… Embeddings extraits\")\n",
    "    print(f\"   â€¢ Shape : {embeddings.shape}\")\n",
    "    print(f\"   â€¢ Dimension : {embeddings.shape[1]}\")\n",
    "    print(f\"   â€¢ Nombre d'exemples : {embeddings.shape[0]:,}\")\n",
    "    print(f\"   â€¢ Min : {embeddings.min():.4f}\")\n",
    "    print(f\"   â€¢ Max : {embeddings.max():.4f}\")\n",
    "    print(f\"   â€¢ Mean : {embeddings.mean():.4f}\")\n",
    "    print(f\"   â€¢ Std : {embeddings.std():.4f}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f78b34",
   "metadata": {},
   "source": [
    "# ğŸ”¬ CELLULE 12 : Application t-SNE, UMAP, PaCMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘         RÃ‰DUCTION DE DIMENSIONNALITÃ‰ : t-SNE, UMAP, PaCMAP               â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Objectif : Visualiser les embeddings MLP en 2D\n",
    "Permet de voir si le rÃ©seau a appris Ã  sÃ©parer les classes\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”¬ COMPARAISON DES MÃ‰THODES DE RÃ‰DUCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFIER ET INSTALLER LES PACKAGES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸ“¦ VÃ©rification des packages...\")\n",
    "\n",
    "# UMAP\n",
    "try:\n",
    "    import umap\n",
    "    print(\"   âœ… UMAP disponible\")\n",
    "except ImportError:\n",
    "    print(\"   ğŸ“¥ Installation de UMAP...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"umap-learn\", \"-q\"], check=True)\n",
    "    import umap\n",
    "    print(\"   âœ… UMAP installÃ©\")\n",
    "\n",
    "# PaCMAP\n",
    "try:\n",
    "    import pacmap\n",
    "    print(\"   âœ… PaCMAP disponible\")\n",
    "except ImportError:\n",
    "    print(\"   ğŸ“¥ Installation de PaCMAP...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"pacmap\", \"-q\"], check=True)\n",
    "    import pacmap\n",
    "    print(\"   âœ… PaCMAP installÃ©\")\n",
    "\n",
    "# ============================================================================\n",
    "# APPLICATION DES 3 MÃ‰THODES\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"â³ APPLICATION DES RÃ‰DUCTIONS (estimation : 1-2 minutes)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. t-SNE\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nğŸ”„ [1/3] t-SNE en cours...\")\n",
    "start = time.time()\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2, \n",
    "    random_state=RANDOM_SEED, \n",
    "    perplexity=30, \n",
    "    n_iter=1000, \n",
    "    verbose=0\n",
    ")\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "time_tsne = time.time() - start\n",
    "\n",
    "print(f\"   âœ… t-SNE terminÃ© en {time_tsne:.2f}s\")\n",
    "results['t-SNE'] = {'data': embeddings_tsne, 'time': time_tsne}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. UMAP\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nğŸ”„ [2/3] UMAP en cours...\")\n",
    "start = time.time()\n",
    "\n",
    "reducer_umap = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "embeddings_umap = reducer_umap.fit_transform(embeddings)\n",
    "time_umap = time.time() - start\n",
    "\n",
    "print(f\"   âœ… UMAP terminÃ© en {time_umap:.2f}s\")\n",
    "results['UMAP'] = {'data': embeddings_umap, 'time': time_umap}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. PaCMAP\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nğŸ”„ [3/3] PaCMAP en cours...\")\n",
    "start = time.time()\n",
    "\n",
    "reducer_pacmap = pacmap.PaCMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    MN_ratio=0.5,\n",
    "    FP_ratio=2.0,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "embeddings_pacmap = reducer_pacmap.fit_transform(embeddings, init=\"pca\")\n",
    "time_pacmap = time.time() - start\n",
    "\n",
    "print(f\"   âœ… PaCMAP terminÃ© en {time_pacmap:.2f}s\")\n",
    "results['PaCMAP'] = {'data': embeddings_pacmap, 'time': time_pacmap}\n",
    "\n",
    "# ============================================================================\n",
    "# CALCUL DES MÃ‰TRIQUES DE CLUSTERING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nğŸ“Š Calcul des mÃ©triques de qualitÃ©...\")\n",
    "\n",
    "metrics = {}\n",
    "for name, result in results.items():\n",
    "    data = result['data']\n",
    "    \n",
    "    # Silhouette Score : mesure la sÃ©paration des clusters\n",
    "    sil = silhouette_score(data, y_true)\n",
    "    \n",
    "    # Davies-Bouldin Index : mesure la compacitÃ© des clusters\n",
    "    db = davies_bouldin_score(data, y_true)\n",
    "    \n",
    "    metrics[name] = {\n",
    "        'silhouette': sil,\n",
    "        'davies_bouldin': db,\n",
    "        'time': result['time']\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TABLEAU COMPARATIF\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š ANALYSE QUANTITATIVE - EMBEDDINGS MLP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'MÃ©thode':<10} {'Silhouette':<15} {'Davies-B':<15} {'Temps (s)':<12} {'QualitÃ©'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for method in ['t-SNE', 'UMAP', 'PaCMAP']:\n",
    "    scores = metrics[method]\n",
    "    sil = scores['silhouette']\n",
    "    db = scores['davies_bouldin']\n",
    "    t = scores['time']\n",
    "    \n",
    "    # Ã‰valuation qualitative\n",
    "    if sil > 0.7:\n",
    "        quality = \"ğŸ¥‡ Excellente\"\n",
    "    elif sil > 0.5:\n",
    "        quality = \"ğŸ¥ˆ TrÃ¨s bonne\"\n",
    "    elif sil > 0.4:\n",
    "        quality = \"ğŸ¥‰ Bonne\"\n",
    "    elif sil > 0.3:\n",
    "        quality = \"âœ“ Correcte\"\n",
    "    else:\n",
    "        quality = \"âš ï¸  ModÃ©rÃ©e\"\n",
    "    \n",
    "    print(f\"{method:<10} {sil:>6.4f} {'':8} {db:>6.4f} {'':8} {t:>6.2f} {'':5} {quality}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CLASSEMENTS\n",
    "# ============================================================================\n",
    "\n",
    "best_quality = max(metrics.items(), key=lambda x: x[1]['silhouette'])\n",
    "fastest = min(metrics.items(), key=lambda x: x[1]['time'])\n",
    "best_db = min(metrics.items(), key=lambda x: x[1]['davies_bouldin'])\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ† CLASSEMENTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Meilleure sÃ©paration : {best_quality[0]} (Silhouette = {best_quality[1]['silhouette']:.4f})\")\n",
    "print(f\"   Plus rapide          : {fastest[0]} ({fastest[1]['time']:.2f}s)\")\n",
    "print(f\"   Meilleur DB Index    : {best_db[0]} ({best_db[1]['davies_bouldin']:.4f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# RECOMMANDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ’¡ RECOMMANDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "speedup_umap = time_tsne / time_umap\n",
    "speedup_pacmap = time_tsne / time_pacmap\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ“ t-SNE   : {metrics['t-SNE']['silhouette']:.3f} silhouette, mais {speedup_umap:.1f}Ã— plus lent qu'UMAP\n",
    "âœ“ UMAP    : {metrics['UMAP']['silhouette']:.3f} silhouette, excellent compromis vitesse/qualitÃ©\n",
    "âœ“ PaCMAP  : {metrics['PaCMAP']['silhouette']:.3f} silhouette, {speedup_pacmap:.1f}Ã— plus rapide que t-SNE\n",
    "\n",
    "Recommandation : {best_quality[0]} offre la meilleure sÃ©paration des classes\n",
    "â†’ Le MLP a bien appris Ã  sÃ©parer les chiffres dans l'espace latent !\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66fb60",
   "metadata": {},
   "source": [
    "# ğŸ¨ CELLULE 13 : Graphique - Comparaison 1Ã—3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84175e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘        GRAPHIQUE : COMPARAISON t-SNE, UMAP, PaCMAP (1Ã—3)                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Š GÃ©nÃ©ration du graphique : Comparaison 1Ã—3\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "fig.suptitle('Comparaison des MÃ©thodes de RÃ©duction - Embeddings MLP\\n'\n",
    "             'Chaque point = 1 image du test set (10,000 images)',\n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "methods_plot = [\n",
    "    ('t-SNE', embeddings_tsne, axes[0], 'PrÃ©serve les voisinages locaux'),\n",
    "    ('UMAP', embeddings_umap, axes[1], 'PrÃ©serve la topologie globale'),\n",
    "    ('PaCMAP', embeddings_pacmap, axes[2], 'Ã‰quilibre local/global')\n",
    "]\n",
    "\n",
    "for method_name, data, ax, subtitle in methods_plot:\n",
    "    # Scatter plot\n",
    "    scatter = ax.scatter(\n",
    "        data[:, 0], data[:, 1],\n",
    "        c=y_true, cmap='tab10', \n",
    "        alpha=0.6, s=30,\n",
    "        edgecolors='black', linewidth=0.2\n",
    "    )\n",
    "    \n",
    "    # Titre et labels\n",
    "    ax.set_title(f'{method_name} - Embeddings MLP\\n{subtitle}',\n",
    "                 fontsize=14, pad=10, fontweight='bold')\n",
    "    ax.set_xlabel(f'{method_name} Dimension 1', fontsize=12)\n",
    "    ax.set_ylabel(f'{method_name} Dimension 2', fontsize=12)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Annotation temps + qualitÃ©\n",
    "    time_text = (f\"â±ï¸ {results[method_name]['time']:.2f}s\\n\"\n",
    "                f\"ğŸ“Š Silhouette: {metrics[method_name]['silhouette']:.3f}\")\n",
    "    ax.text(0.02, 0.98, time_text, transform=ax.transAxes,\n",
    "           fontsize=10, verticalalignment='top', fontweight='bold',\n",
    "           bbox=dict(boxstyle='round,pad=0.5', facecolor='white', \n",
    "                    alpha=0.9, edgecolor='black', linewidth=1.5))\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, ticks=range(10))\n",
    "    cbar.set_label('Chiffre', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'mlp_embeddings_comparison_1x3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Graphique sauvegardÃ© : {GRAPH_DIR / 'mlp_embeddings_comparison_1x3.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a444ee",
   "metadata": {},
   "source": [
    "# ğŸ”¢ CELLULE 14 : Graphique - Vue par Classe (3Ã—10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04438b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘             GRAPHIQUE : VUE PAR CLASSE (grille 3Ã—10)                     â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Š GÃ©nÃ©ration du graphique : Vue par classe (3Ã—10)\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 10, figsize=(28, 10))\n",
    "fig.suptitle('Vue par Classe - Embeddings MLP\\n'\n",
    "             'Chaque sous-graphe montre oÃ¹ se situent les exemples d\\'un chiffre spÃ©cifique',\n",
    "             fontsize=16, fontweight='bold', y=0.998)\n",
    "\n",
    "methods_data = [\n",
    "    ('t-SNE', embeddings_tsne),\n",
    "    ('UMAP', embeddings_umap),\n",
    "    ('PaCMAP', embeddings_pacmap)\n",
    "]\n",
    "\n",
    "for row, (method_name, data) in enumerate(methods_data):\n",
    "    for digit in range(10):\n",
    "        ax = axes[row, digit]\n",
    "        \n",
    "        # Masque pour le chiffre actuel\n",
    "        mask_digit = (y_true == digit)\n",
    "        \n",
    "        # Background (tous les autres chiffres en gris)\n",
    "        ax.scatter(data[~mask_digit, 0], data[~mask_digit, 1],\n",
    "                   c='lightgray', alpha=0.15, s=5)\n",
    "        \n",
    "        # Chiffre actuel en couleur\n",
    "        ax.scatter(data[mask_digit, 0], data[mask_digit, 1],\n",
    "                   c=f'C{digit}', alpha=0.8, s=20,\n",
    "                   edgecolors='black', linewidth=0.2)\n",
    "        \n",
    "        # Labels\n",
    "        if digit == 0:\n",
    "            ax.set_ylabel(f'{method_name}\\nMLP',\n",
    "                         fontsize=12, fontweight='bold',\n",
    "                         rotation=0, labelpad=40, va='center')\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(f'Chiffre {digit}',\n",
    "                        fontsize=11, fontweight='bold')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(alpha=0.2, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'mlp_embeddings_per_class_3x10.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Graphique sauvegardÃ© : {GRAPH_DIR / 'mlp_embeddings_per_class_3x10.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654a81f",
   "metadata": {},
   "source": [
    "# âš¡ CELLULE 15 : Graphique - Performance vs QualitÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘          GRAPHIQUE : COMPROMIS VITESSE vs QUALITÃ‰                        â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Š GÃ©nÃ©ration du graphique : Compromis vitesse/qualitÃ©\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "methods_list = ['t-SNE', 'UMAP', 'PaCMAP']\n",
    "times = [metrics[m]['time'] for m in methods_list]\n",
    "silhouettes = [metrics[m]['silhouette'] for m in methods_list]\n",
    "colors = ['#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "# Points\n",
    "for i, method in enumerate(methods_list):\n",
    "    ax.scatter(times[i], silhouettes[i], s=600, c=colors[i], alpha=0.7,\n",
    "              edgecolors='black', linewidth=3, zorder=3)\n",
    "    \n",
    "    # Annotations\n",
    "    ax.annotate(f'{method}\\n(MLP Embeddings)',\n",
    "               (times[i], silhouettes[i]),\n",
    "               fontsize=14, fontweight='bold', ha='center',\n",
    "               xytext=(0, -60), textcoords='offset points',\n",
    "               bbox=dict(boxstyle='round,pad=0.7', facecolor='white',\n",
    "                        edgecolor=colors[i], linewidth=2.5, alpha=0.95),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2.5, color=colors[i]))\n",
    "\n",
    "# Configuration\n",
    "ax.set_xlabel('Temps d\\'exÃ©cution (secondes)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Silhouette Score (qualitÃ© de clustering)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Compromis Vitesse vs QualitÃ© - Embeddings MLP\\n'\n",
    "             'Plus haut et Ã  gauche = mieux',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.grid(alpha=0.4, linestyle='--', linewidth=1)\n",
    "ax.set_xlim(left=-1)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Zones de qualitÃ©\n",
    "ax.axhspan(0.7, 1.0, alpha=0.1, color='green', zorder=0)\n",
    "ax.axhspan(0.5, 0.7, alpha=0.1, color='orange', zorder=0)\n",
    "ax.axhspan(0.3, 0.5, alpha=0.1, color='yellow', zorder=0)\n",
    "\n",
    "# Annotations des zones\n",
    "ax.text(0.98, 0.85, 'Excellente\\n(>0.7)', transform=ax.transAxes,\n",
    "        fontsize=11, ha='right', color='green', fontweight='bold')\n",
    "ax.text(0.98, 0.60, 'TrÃ¨s bonne\\n(0.5-0.7)', transform=ax.transAxes,\n",
    "        fontsize=11, ha='right', color='orange', fontweight='bold')\n",
    "ax.text(0.98, 0.40, 'Bonne\\n(0.3-0.5)', transform=ax.transAxes,\n",
    "        fontsize=11, ha='right', color='goldenrod', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(GRAPH_DIR / 'mlp_speed_quality_tradeoff.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Graphique sauvegardÃ© : {GRAPH_DIR / 'mlp_speed_quality_tradeoff.png'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ANALYSE COMPLÃˆTE TERMINÃ‰E\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ“ Tous les graphiques sauvegardÃ©s dans : {GRAPH_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Handwritten-Digits-Classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
